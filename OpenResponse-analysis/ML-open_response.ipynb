{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and clean data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3051: DtypeWarning: Columns (18,33,34,39,40,65,66,67,68,97,98,125,126,135,136,141,142,167,168,171,172,203,204,218,239,240,241,242,269,270,305,306,311,312,324,349,350,385,386,405,406,413,414) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_complete = pd.read_csv('C:/Users/Cole/Documents/DATA/PLIC_DATA/Collective_Surveys/Complete/Complete_Concat.csv')\n",
    "df_beta = pd.read_excel('C:/Users/Cole/Documents/DATA/PLIC_DATA/Data_from_development/Coded_FR/PLIC_beta_FR_Cole.xlsx').fillna(0)\n",
    "\n",
    "def GetNewResponses(df, Q):\n",
    "    def GetPrePost(df, prepost):\n",
    "        df_temp = df.loc[df['Survey_' + prepost] == 'F', [col for col in df.columns if ((Q in col) & \n",
    "                                                                                        (('_' + prepost) in col) & \n",
    "                                                                                        ('l' not in col))]]\n",
    "        other_col = [col for col in df_temp.columns if 'TEXT' in col][0].split('_')[1]\n",
    "        df_temp = df_temp.loc[:, [col for col in df_temp.columns if other_col not in col]]\n",
    "        df_temp = df_temp.dropna(subset = [col for col in df_temp.columns if col != (Q + '_' + prepost)], how = 'all')\n",
    "        df_temp.columns = [col[:-2] for col in df_temp.columns]\n",
    "        return df_temp\n",
    "        \n",
    "    df_pre = GetPrePost(df, 'x')\n",
    "    df_post = GetPrePost(df, 'y')\n",
    "    return pd.concat([df_pre, df_post], axis = 0).reset_index(drop = True).fillna(0)\n",
    "\n",
    "def GetOldResponses(df, Q, collapse = True):\n",
    "    if(collapse):\n",
    "        df_temp = df.loc[:, [col for col in df_beta.columns if Q in col]]\n",
    "        cols = list(set(['_'.join(col.split('_')[:2]) for col in df_temp.columns if '_' in col]))\n",
    "        cols = [col.replace('.1', '') for col in cols]\n",
    "\n",
    "        for col_new in cols:\n",
    "            df_temp[col_new] = 1 * (df_temp.loc[:, [col for col in df_temp.columns[1:] if \n",
    "                                                    col_new.split('_')[-1] == col.split('_')[1]]].sum(axis = 1) > 0)\n",
    "        df_temp = df_temp.loc[df_temp[cols].sum(axis = 1) > 0, :]\n",
    "        cols.append(Q)\n",
    "        return df_temp[cols].reset_index(drop = True)\n",
    "    \n",
    "def GetAllData(df_old, df_new, Q):\n",
    "    df_old = GetOldResponses(df_old, Q)\n",
    "    df_new = GetNewResponses(df_new, Q)\n",
    "    return pd.concat([df_old, df_new], axis = 0, join = 'outer').loc[:, list(df_new.columns)].reset_index(drop = True).sample(frac = 1, random_state = 11).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scoring = 'f1'\n",
    "CV = 5\n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        Tokenizer = RegexpTokenizer(r'\\w+|%|\\+|\\-')\n",
    "        return [self.wnl.lemmatize(t) for t in Tokenizer.tokenize(doc)]\n",
    "    \n",
    "class StemTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.ps = PorterStemmer()\n",
    "    def __call__(self, doc):\n",
    "        Tokenizer = RegexpTokenizer(r'\\w+|%|\\+|\\-')\n",
    "        return [self.ps.stem(t) for t in Tokenizer.tokenize(doc)]\n",
    "\n",
    "def CodeFR(df, Q, Scoring, CV):\n",
    "    # add stemming\n",
    "    Pipe = Pipeline([\n",
    "                    ('TFIDF', TfidfVectorizer(stop_words = 'english', tokenizer = StemTokenizer(), ngram_range = (1, 2), \n",
    "                                              max_features = 1000)),\n",
    "                    ('SVM', SVC(kernel = 'linear', random_state = 11))\n",
    "                    ])\n",
    "\n",
    "    Params = {\n",
    "            'SVM__C': (0.001, 0.01, 0.1, 1),\n",
    "            }\n",
    "    Grid_Search = GridSearchCV(Pipe, Params, n_jobs = 1, verbose = 1, cv = CV, scoring = Scoring)\n",
    "\n",
    "    X = df[Q]\n",
    "    y = df.drop(Q, axis = 1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 11)\n",
    "    \n",
    "    for col in y_train.columns:\n",
    "        Grid_Search.fit(X_train, y_train.loc[:, col])\n",
    "        y_pred = Grid_Search.predict(X_test)\n",
    "\n",
    "        print(col)\n",
    "        print((metrics.confusion_matrix(y_test.loc[:, col], y_pred))/len(y_test))\n",
    "        print(metrics.f1_score(y_test.loc[:, col], y_pred))\n",
    "        \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Q1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    7.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1b_16\n",
      "[[0.91447368 0.        ]\n",
      " [0.04605263 0.03947368]]\n",
      "0.631578947368421\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    8.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1b_28\n",
      "[[0.84210526 0.00657895]\n",
      " [0.125      0.02631579]]\n",
      "0.2857142857142857\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    8.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1b_2\n",
      "[[0.50657895 0.125     ]\n",
      " [0.06578947 0.30263158]]\n",
      "0.7603305785123968\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    8.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1b_31\n",
      "[[0.90131579 0.01315789]\n",
      " [0.06578947 0.01973684]]\n",
      "0.33333333333333337\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    8.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1b_5\n",
      "[[0.47368421 0.06578947]\n",
      " [0.11184211 0.34868421]]\n",
      "0.7969924812030075\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    8.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1b_8\n",
      "[[0.91447368 0.        ]\n",
      " [0.01973684 0.06578947]]\n",
      "0.8695652173913044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1b = GetAllData(df_beta, df_complete, 'Q1b')\n",
    "CodeFR(df_1b, 'Q1b', Scoring, CV)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

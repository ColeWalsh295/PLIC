{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "os.chdir('C:/Users/Cole/Documents/GitHub/PLIC/Automation-Files/')\n",
    "import Valid_Matched\n",
    "import Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup necessary files and variables for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/Cole/Documents/PLIC_DATA/')\n",
    "Weights = pd.read_excel('Weights_May2019.xlsx').transpose()[0]\n",
    "Basedf = pd.read_csv('PLIC_May2019.csv', nrows = 1)\n",
    "MainSurveys_Folder = 'SurveysMay2019/'\n",
    "Questions = ['Q1b', 'Q1d', 'Q1e', 'Q2b', 'Q2d', 'Q2e', 'Q3b', 'Q3d', 'Q3e', 'Q4b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Valid/Matched Surveys Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConcatValidSurveys(FileList, ValidLocation, ValidFileName):\n",
    "    if not os.path.exists(ValidLocation):\n",
    "        os.mkdir(ValidLocation)\n",
    "\n",
    "    dfs = []\n",
    "    for f in FileList:\n",
    "        Class_ID = 'R_' + f.split('_')[-2]\n",
    "        df = pd.read_csv(f, skiprows = [1], dtype = {'Q5a':'object'})\n",
    "        df['Class_ID'] = Class_ID\n",
    "        df = df[(df['V5'] == 1) & (df['Unnamed: 7'] == 1) & (df['Q6d'] == 2)]\n",
    "        df = df[(df['Qt1_3'] >= 30) | (df['Qt2_3'] >= 30) | (df['Qt3_3'] >= 30) | (df['Qt4_3'] >= 30)]\n",
    "        df = df.drop_duplicates(subset = ['Q5b', 'Q5c'])\n",
    "        if('Survey' not in df.columns):\n",
    "            df['Survey'] = 'C'\n",
    "\n",
    "        Items = [c for c in df.columns for Q in Questions if Q in c and 'TEXT' not in c and 'l' not in c and '_' in c]\n",
    "        df[Items] = df[Items].fillna('0').astype(str).apply(lambda x: x.str.replace('^(?!0*$).*$', \n",
    "                                                                                    '1')).astype(float).replace(0, np.nan)\n",
    "\n",
    "        df.to_csv(ValidLocation + f.replace('\\\\', '/').split('/')[-1].split('.')[0] + '_Valid.csv', index = False)\n",
    "        dfs.append(df)\n",
    "        \n",
    "    df = pd.concat(dfs, axis = 0)\n",
    "    df.to_csv('Collective_Surveys/' + ValidFileName, index = False)\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "def ConcatMatchedSurveys(PreFileList, PostFileList, PreMatchedLocation, PostMatchedLocation, PreCollectiveSurveyName, \n",
    "                         PostCollectiveSurveyName):\n",
    "    if not os.path.exists(PreMatchedLocation):\n",
    "        os.mkdir(PreMatchedLocation)\n",
    "    if not os.path.exists(PostMatchedLocation):\n",
    "        os.mkdir(PostMatchedLocation)\n",
    "    \n",
    "    Predfs = []\n",
    "    Postdfs = []\n",
    "    for f_pre in PreFileList:\n",
    "        for f_post in PostFileList:\n",
    "            if(f_pre.split('_')[-2] != f_post.split('_')[-2]):\n",
    "                continue\n",
    "            print(f_pre)\n",
    "            Class_ID = 'R_' + f_pre.split('_')[-2] # Split of the underscore at the end for the new format\n",
    "            # Change Valid_Matched to version of matching algorithm being used\n",
    "            NPre, NPost, dfPre, dfPost = Valid_Matched.ValMat(PRE = pd.read_csv(f_pre, skiprows = [1], dtype = {'Q5a':'object'}), \n",
    "                                                              POST = pd.read_csv(f_post, skiprows = [1], dtype = {'Q5a':'object'}))\n",
    "            if('Survey' not in dfPre.columns):\n",
    "                dfPre['Survey'] = 'C'\n",
    "            if('Survey' not in dfPost.columns):\n",
    "                dfPost['Survey'] = 'C'\n",
    "            dfPre['Class_ID'] = Class_ID\n",
    "            dfPost['Class_ID'] = Class_ID\n",
    "            Predfs.append(dfPre)\n",
    "            Postdfs.append(dfPost)\n",
    "\n",
    "            dfPre.to_csv(PreMatchedLocation + f_pre.replace('\\\\', '/').split('/')[-1].split('.')[0] + '_ValMat.csv', \n",
    "                           index = False)\n",
    "            dfPost.to_csv(PostMatchedLocation + f_post.replace('\\\\', '/').split('/')[-1].split('.')[0] + '_ValMat.csv', \n",
    "                            index = False)\n",
    "            \n",
    "            break\n",
    "    \n",
    "    dfPre_Matched = pd.concat(Predfs, join = 'outer', axis = 0).reset_index(drop = True)\n",
    "    dfPost_Matched = pd.concat(Postdfs, join = 'outer', axis = 0).reset_index(drop = True)\n",
    "\n",
    "    dfPre_Matched.to_csv('Collective_Surveys/PRE_Valid_Matched/' + PreCollectiveSurveyName, index = False)\n",
    "    dfPost_Matched.to_csv('Collective_Surveys/POST_Valid_Matched/' + PostCollectiveSurveyName, index = False)\n",
    "\n",
    "    return(dfPre_Matched, dfPost_Matched)\n",
    "\n",
    "def ConsentAtPost(PRE_Valid_File, PRE_Valid_Matched_File):\n",
    "    Valid_df = pd.read_csv(PRE_Valid_File, dtype = {'Q5a':'object'})\n",
    "    Matched_df = pd.read_csv(PRE_Valid_Matched_File, dtype = {'Q5a':'object'})\n",
    "\n",
    "    # Add Pre-Surveys from matched set to overall set who enacted consent at POST\n",
    "    ActualllyValidPre = Matched_df[~Matched_df['V1'].isin(Valid_df['V1'])]\n",
    "    Total_Valid_df = pd.concat([Valid_df, ActualllyValidPre], join = 'inner', axis = 0)\n",
    "    \n",
    "    Total_Valid_df.to_csv(PRE_Valid_File, index = False)\n",
    "    \n",
    "    return(Total_Valid_df)\n",
    "\n",
    "def MergeSurveys(PRE_Matched_File, POST_Matched_File, FileName):\n",
    "    PRE_df = pd.read_csv(PRE_Matched_File, dtype = {'Q5a':'object'})\n",
    "    POST_df = pd.read_csv(POST_Matched_File, dtype = {'Q5a':'object'})\n",
    "    \n",
    "    PRE_df_S = Scoring.CalcScore(PRE_df, Weights)\n",
    "    POST_df_S = Scoring.CalcScore(POST_df, Weights)\n",
    "\n",
    "    PRE_df_S = PRE_df_S.rename(columns = {'TotalScores':'PreScores'})\n",
    "    POST_df_S = POST_df_S.rename(columns = {'TotalScores':'PostScores'})\n",
    "\n",
    "    PRE_df_S['FullName'] = PRE_df_S['Q5b'].str.lower().str.replace(' ', '') + PRE_df_S['Q5c'].str.lower().str.replace(' ', '')\n",
    "    POST_df_S['FullName'] = POST_df_S['Q5b'].str.lower().str.replace(' ', '') + POST_df_S['Q5c'].str.lower().str.replace(' ', '')\n",
    "    POST_df_S['BackName'] = POST_df_S['Q5c'].str.lower().str.replace(' ', '') + POST_df_S['Q5b'].str.lower().str.replace(' ', '')\n",
    "    \n",
    "    Full_df = pd.merge(left = PRE_df_S, right = POST_df_S, how = 'inner', on = ['Class_ID', 'FullName'])\n",
    "    Back_df = pd.merge(left = PRE_df_S, right = POST_df_S, how = 'inner', left_on = ['Class_ID', 'FullName'], \n",
    "                   right_on = ['Class_ID', 'BackName'])\n",
    "    ID_df = pd.merge(left = PRE_df_S, right = POST_df_S, how = 'inner', on = ['Class_ID', \n",
    "                                                                              'Q5a']).rename(columns = {'Q5a':'Q5a_x'})\n",
    "    ID_df['Q5a_y'] = ID_df['Q5a_x']\n",
    "    \n",
    "    Merged_df = pd.concat([Full_df, Back_df, ID_df], axis = 0, \n",
    "                          join = 'inner').drop_duplicates().drop(columns = ['BackName']).reset_index(drop = True)\n",
    "    \n",
    "    if('Q4b' in Merged_df.columns):\n",
    "        Merged_df = Merged_df.rename(columns = {'Q1b':'Q1b_x', 'Q1d':'Q1d_x', 'Q1e':'Q1e_x', 'Q2b':'Q2b_x', 'Q2d':'Q2d_x',\n",
    "                                                'Q2e':'Q2e_x', 'Q3b':'Q3b_x', 'Q3d':'Q3d_x', 'Q3e':'Q3e_x', 'Q4b':'Q4b_x'})\n",
    "    \n",
    "    Merged_df.to_csv('Collective_Surveys/Merged/' + FileName, index = False)\n",
    "    \n",
    "    return(Merged_df)\n",
    "\n",
    "def MergePlusMissing(MergedFile, ValidPRE_File, ValidPOST_File, CompleteFileName):\n",
    "    \n",
    "    Merged_df = pd.read_csv('Collective_Surveys/Merged/' + MergedFile)\n",
    "\n",
    "    PRE_df = pd.read_csv('Collective_Surveys/PRE_Valid/' + ValidPRE_File)\n",
    "    POST_df = pd.read_csv('Collective_Surveys/POST_Valid/' + ValidPOST_File)\n",
    "\n",
    "    PRE_df_S = Scoring.CalcScore(PRE_df, Weights).rename(columns = {'TotalScores':'PreScores'})\n",
    "    POST_df_S = Scoring.CalcScore(POST_df, Weights).rename(columns = {'TotalScores':'PostScores'})\n",
    "\n",
    "    Unmatched_PRE = PRE_df_S[~PRE_df_S['V1'].isin(Merged_df['V1_x'])]\n",
    "    Unmatched_POST = POST_df_S[~POST_df_S['V1'].isin(Merged_df['V1_y'])]\n",
    "\n",
    "    Unmatched_PRE.columns = [c + '_x' if c != 'Class_ID' and c != 'PreScores' else c for c in Unmatched_PRE.columns]\n",
    "    Unmatched_POST.columns = [c + '_y' if c != 'Class_ID' and c != 'PostScores' else c for c in Unmatched_POST.columns]\n",
    "\n",
    "    Complete_df = pd.concat([Merged_df, Unmatched_PRE, Unmatched_POST], axis = 0, join = 'outer')\n",
    "    Complete_df = Complete_df[Merged_df.columns]\n",
    "    Complete_df.to_csv('Collective_Surveys/Complete/' + CompleteFileName, index = False)\n",
    "\n",
    "    return(Complete_df)\n",
    "\n",
    "def ConcatSurveys(Semester, Year):\n",
    "    PreFiles = glob(MainSurveys_Folder + Semester + Year + '/PRE/*.csv')\n",
    "    PostFiles = glob(MainSurveys_Folder + Semester + Year + '/POST/*.csv')\n",
    "\n",
    "    PREValid = ConcatValidSurveys(PreFiles, MainSurveys_Folder + Semester + Year + '/PRE/Valid/',\n",
    "                                  'PRE_Valid/' + Semester + Year + '_PRE_Valid.csv')\n",
    "    POSTValid = ConcatValidSurveys(PostFiles, MainSurveys_Folder + Semester + Year + '/POST/Valid/',\n",
    "                                   'POST_Valid/' + Semester + Year + '_POST_Valid.csv')\n",
    "\n",
    "    PREValMat, POSTValMat = ConcatMatchedSurveys(PreFiles, PostFiles,\n",
    "                                                 MainSurveys_Folder + Semester + Year + '/PRE/Valid/Matched/',\n",
    "                                                 MainSurveys_Folder + Semester + Year + '/POST/Valid/Matched/',\n",
    "                                                 Semester + Year + '_PRE_ValMat.csv',\n",
    "                                                 Semester + Year + '_POST_ValMat.csv')\n",
    "\n",
    "    PREValid = ConsentAtPost('Collective_Surveys/PRE_Valid/' + Semester + Year + '_PRE_Valid.csv',\n",
    "                             'Collective_Surveys/PRE_Valid_Matched/' + Semester + Year + '_PRE_ValMat.csv')\n",
    "    \n",
    "    return(PREValMat, POSTValMat)\n",
    "\n",
    "def CompleteConcat(FolderName):\n",
    "    Files = [f for f in glob('Collective_Surveys/' + FolderName + '/*') if 'Concat' not in f]\n",
    "    \n",
    "    print(Files)\n",
    "    \n",
    "    dfs = [pd.read_csv(f) for f in Files]\n",
    "    df = pd.concat(dfs, join = 'outer', axis = 0)\n",
    "    df.to_csv('Collective_Surveys/' + FolderName + '/' + FolderName + '_Concat.csv', index = False)\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate Fall 2017 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Finished'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3077\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3078\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3079\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Finished'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a5980dcff08e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mFall2017_PREValMat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFall2017_POSTValMat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConcatSurveys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Fall'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'2017'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mFall2017_POSTValMat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m86\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Q5c'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Chris'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mFall2017_POSTValMat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m124\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Q5c'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Will'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mFall2017_PREValMat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m242\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Q5c'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Ray'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-8eafb8c07bde>\u001b[0m in \u001b[0;36mConcatSurveys\u001b[1;34m(Semester, Year)\u001b[0m\n\u001b[0;32m    147\u001b[0m                                                  \u001b[0mMainSurveys_Folder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mSemester\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mYear\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/POST/Valid/Matched/'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m                                                  \u001b[0mSemester\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mYear\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_PRE_ValMat.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m                                                  Semester + Year + '_POST_ValMat.csv')\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     PREValid = ConsentAtPost('Collective_Surveys/PRE_Valid/' + Semester + Year + '_PRE_Valid.csv',\n",
      "\u001b[1;32m<ipython-input-3-8eafb8c07bde>\u001b[0m in \u001b[0;36mConcatMatchedSurveys\u001b[1;34m(PreFileList, PostFileList, PreMatchedLocation, PostMatchedLocation, PreCollectiveSurveyName, PostCollectiveSurveyName)\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;31m# Change Valid_Matched to version of matching algorithm being used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             NPre, NPost, dfPre, dfPost = Valid_Matched.ValMat(PRE = pd.read_csv(f_pre, skiprows = [1]), \n\u001b[1;32m---> 45\u001b[1;33m                                                               POST = pd.read_csv(f_post, skiprows = [1]))\n\u001b[0m\u001b[0;32m     46\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Survey'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdfPre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m                 \u001b[0mdfPre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Survey'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'C'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\PLIC\\Automation-Files\\Valid_Matched.py\u001b[0m in \u001b[0;36mValMat\u001b[1;34m(DoMatch, **Dataframes)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mValMat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDoMatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mDataframes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mdfPost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataframes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'POST'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mdfPost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mValidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfPost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'POST'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mNValidPost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfPost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'PRE'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mDataframes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\PLIC\\Automation-Files\\Valid_Matched.py\u001b[0m in \u001b[0;36mValidate\u001b[1;34m(df, Survey)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mValidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSurvey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSurvey\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'POST'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Finished'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Unnamed: 8'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Q6d'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# Drop students who are not consenting, did not finish, or are not at least 18 at Post\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;31m# df = df[(df['V5'] == 1) & (df['Unnamed: 7'] == 1) & (df['Q6d'] == 2)]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2686\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2687\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2688\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2693\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2695\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2697\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2489\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   4113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4114\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4115\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4116\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3078\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Finished'"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "\n",
    "Fall2017_PREValMat, Fall2017_POSTValMat = ConcatSurveys('Fall', '2017')\n",
    "\n",
    "Fall2017_POSTValMat.loc[86, 'Q5c'] = 'Chris'\n",
    "Fall2017_POSTValMat.loc[124, 'Q5c'] = 'Will'\n",
    "Fall2017_PREValMat.loc[242, 'Q5c'] = 'Ray'\n",
    "Fall2017_PREValMat.loc[270, 'Q5c'] = 'Chris'\n",
    "Fall2017_PREValMat.loc[195, 'Q5c'] = 'Ben'\n",
    "Fall2017_POSTValMat.loc[228, 'Q5c'] = 'Theo'\n",
    "Fall2017_POSTValMat.loc[320, 'Q5c'] = 'Santi'\n",
    "Fall2017_POSTValMat.loc[347, 'Q5c'] = 'Zac'\n",
    "Fall2017_PREValMat.loc[417, 'Q5b'] = 'StLouis'\n",
    "Fall2017_POSTValMat.loc[509, 'Q5c'] = 'Omar'\n",
    "Fall2017_POSTValMat.loc[529, 'Q5c'] = 'Brad'\n",
    "\n",
    "Fall2017_PREValMat.to_csv('Collective_Surveys/PRE_Valid_Matched/Fall2017_PRE_ValMat.csv', index = False)\n",
    "Fall2017_POSTValMat.to_csv('Collective_Surveys/POST_Valid_Matched/Fall2017_POST_ValMat.csv', index = False)\n",
    "\n",
    "Fall2017_Matched = MergeSurveys('Collective_Surveys/PRE_Valid_Matched/Fall2017_PRE_ValMat.csv',\n",
    "                                'Collective_Surveys/POST_Valid_Matched/Fall2017_POST_ValMat.csv',\n",
    "                                'Fall2017_Merged.csv')\n",
    "\n",
    "Fall2017_Complete = MergePlusMissing('Fall2017_Merged.csv', 'Fall2017_PRE_Valid.csv', 'Fall2017_POST_Valid.csv', \n",
    "                                     'Fall2017_Complete.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate Spring 2018 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "Spring2018_PREValMat, Spring2018_POSTValMat = ConcatSurveys('Spring', '2018')\n",
    "\n",
    "Spring2018_PREValMat.loc[8, 'Q5c'] = 'Joshua'\n",
    "Spring2018_PREValMat.loc[12, 'Q5c'] = 'Daria'\n",
    "Spring2018_POSTValMat.loc[5, 'Q5c'] = 'Greg'\n",
    "Spring2018_POSTValMat.loc[148, 'Q5c'] = 'Edward'\n",
    "Spring2018_PREValMat.loc[388, 'Q5c'] = 'Mourud'\n",
    "\n",
    "Spring2018_PREValMat.to_csv('Collective_Surveys/PRE_Valid_Matched/Spring2018_PRE_ValMat.csv', index = False)\n",
    "Spring2018_POSTValMat.to_csv('Collective_Surveys/POST_Valid_Matched/Spring2018_POST_ValMat.csv', index = False)\n",
    "\n",
    "Spring2018_Matched = MergeSurveys('Collective_Surveys/PRE_Valid_Matched/Spring2018_PRE_ValMat.csv', \n",
    "                                  'Collective_Surveys/POST_Valid_Matched/Spring2018_POST_ValMat.csv',\n",
    "                                  'Spring2018_Merged.csv')\n",
    "\n",
    "Spring2018_Complete = MergePlusMissing('Spring2018_Merged.csv', 'Spring2018_PRE_Valid.csv', 'Spring2018_POST_Valid.csv',\n",
    "                                       'Spring2018_Complete.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate Fall 2018 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "Fall2018_PREValMat, Fall2018_POSTValMat = ConcatSurveys('Fall', '2018')\n",
    "\n",
    "Fall2018_PREValMat.loc[8, 'Q5c'] = 'Alex'\n",
    "Fall2018_POSTValMat.loc[50, 'Q5c'] = 'Alex'\n",
    "Fall2018_PREValMat.loc[280, 'Q5a'] = '900725834'\n",
    "Fall2018_PREValMat.loc[380, 'Q5c'] = 'Chris'\n",
    "Fall2018_POSTValMat.loc[581, 'Q5c'] = 'Christopher'\n",
    "Fall2018_PREValMat.loc[606, 'Q5c'] = 'Cece'\n",
    "Fall2018_PREValMat.loc[716, 'Q5c'] = 'Ben'\n",
    "Fall2018_POSTValMat.loc[737, 'Q5c'] = 'Sam'\n",
    "Fall2018_POSTValMat.loc[730, 'Q5c'] = 'Rob'\n",
    "Fall2018_PREValMat.loc[1042, 'Q5c'] = 'Kamsi'\n",
    "Fall2018_POSTValMat.loc[1028, 'Q5c'] = 'Alex'\n",
    "Fall2018_POSTValMat.loc[1054, 'Q5c'] = 'Tiffany'\n",
    "Fall2018_POSTValMat.loc[1167, 'Q5c'] = 'Alex'\n",
    "\n",
    "Fall2018_PREValMat.to_csv('Collective_Surveys/PRE_Valid_Matched/Fall2018_PRE_ValMat.csv', index = False)\n",
    "Fall2018_POSTValMat.to_csv('Collective_Surveys/POST_Valid_Matched/Fall2018_POST_ValMat.csv', index = False)\n",
    "\n",
    "Fall2018_Matched = MergeSurveys('Collective_Surveys/PRE_Valid_Matched/Fall2018_PRE_ValMat.csv', \n",
    "                                'Collective_Surveys/POST_Valid_Matched/Fall2018_POST_ValMat.csv',\n",
    "                                'Fall2018_Merged.csv')\n",
    "\n",
    "Fall2018_Complete = MergePlusMissing('Fall2018_Merged.csv', 'Fall2018_PRE_Valid.csv', 'Fall2018_POST_Valid.csv',\n",
    "                                     'Fall2018_Complete.csv')\n",
    "\n",
    "Out_Predf = Fall2018_PREValMat[~Fall2018_PREValMat['V1'].isin(Fall2018_Matched['V1_x'])]\n",
    "Out_Postdf = Fall2018_POSTValMat[~Fall2018_POSTValMat['V1'].isin(Fall2018_Matched['V1_y'])]\n",
    "\n",
    "print(Out_Predf[['Q5a', 'Q5b', 'Q5c']])\n",
    "print(Out_Postdf[['Q5a', 'Q5b', 'Q5c']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate Spring 2019 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "Spring2019_PREValMat, Spring2019_POSTValMat = ConcatSurveys('Spring', '2019')\n",
    "\n",
    "Spring2019_POSTValMat.loc[27, 'Q5b'] = 'Rocha'\n",
    "Spring2019_POSTValMat.loc[115, 'Q5c'] = 'Alex'\n",
    "Spring2019_PREValMat.loc[131, 'Q5c'] = 'Zach'\n",
    "Spring2019_PREValMat.loc[194, 'Q5c'] = 'Josh' \n",
    "Spring2019_PREValMat.loc[651, 'Q5c'] = 'Tim'\n",
    "Spring2019_POSTValMat.loc[705, 'Q5c'] = 'Josh'\n",
    "\n",
    "Spring2019_PREValMat.to_csv('Collective_Surveys/PRE_Valid_Matched/Spring2019_PRE_ValMat.csv', index = False)\n",
    "Spring2019_POSTValMat.to_csv('Collective_Surveys/POST_Valid_Matched/Spring2019_POST_ValMat.csv', index = False)\n",
    "\n",
    "Spring2019_Matched = MergeSurveys('Collective_Surveys/PRE_Valid_Matched/Spring2019_PRE_ValMat.csv', \n",
    "                                'Collective_Surveys/POST_Valid_Matched/Spring2019_POST_ValMat.csv',\n",
    "                                'Spring2019_Merged.csv')\n",
    "\n",
    "Out_Predf = Spring2019_PREValMat[~Spring2019_PREValMat['V1'].isin(Spring2019_Matched['V1_x'])]\n",
    "Out_Postdf = Spring2019_POSTValMat[~Spring2019_POSTValMat['V1'].isin(Spring2019_Matched['V1_y'])]\n",
    "\n",
    "print(Out_Predf[['Q5a', 'Q5b', 'Q5c']])\n",
    "print(Out_Postdf[['Q5a', 'Q5b', 'Q5c']])\n",
    "\n",
    "Spring2019_Complete = MergePlusMissing('Spring2019_Merged.csv', 'Spring2019_PRE_Valid.csv', 'Spring2019_POST_Valid.csv',\n",
    "                                       'Spring2019_Complete.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate Fall 2019 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SurveysMay2019/Fall2019/PRE\\Fall2019_Agnes_Scott_College_202_Marine_PRE_R_2Cmq05OZWF8UESV_May2019.csv\n",
      "SurveysMay2019/Fall2019/PRE\\Fall2019_Barnard_College_PHYS2001_Savin_PRE_R_2Cx014FHcWCOw9u_May2019.csv\n",
      "SurveysMay2019/Fall2019/PRE\\Fall2019_Bethel_University_PHY_292D_Hogan_PRE_R_XH3AUfCAn0ph6Hn_May2019.csv\n",
      "SurveysMay2019/Fall2019/PRE\\Fall2019_Cornell_University_Phys6510_Holmes_PRE_R_2XhpZkn4DGP598r_May2019.csv\n",
      "SurveysMay2019/Fall2019/PRE\\Fall2019_Cornell_University_Phys_1112_Holmes_PRE_R_9EVBSZgwQyP6mWZ_May2019.csv\n",
      "SurveysMay2019/Fall2019/PRE\\Fall2019_Cornell_University_Phys_2213_Holmes_PRE_R_31hmnBMkK3Bvc3z_May2019.csv\n",
      "SurveysMay2019/Fall2019/PRE\\Fall2019_Cornell_University_Phys_2218_Holmes_PRE_R_1pyQ0Ym19YJPe3Q_May2019.csv\n",
      "SurveysMay2019/Fall2019/PRE\\Fall2019_Penn_State_University_PHYS_457_Purdy_Drew_PRE_R_3q88ROCl8ybpqTf_May2019.csv\n",
      "SurveysMay2019/Fall2019/PRE\\Fall2019_Salem_State_University_PHS_311_Conlin_PRE_R_2cC5NePDupfT60Q_May2019.csv\n",
      "SurveysMay2019/Fall2019/PRE\\Fall2019_Siena_College_PHYS_110_Bellis_PRE_R_8pSv1l25MISvI1b_May2019.csv\n",
      "SurveysMay2019/Fall2019/PRE\\Fall2019_Siena_College_PHYS_130_Bellis_PRE_R_2ya8AVehEblzXcn_May2019.csv\n",
      "SurveysMay2019/Fall2019/PRE\\Fall2019_University_of_Chicago_Department_of_Physics_121_Chantell_PRE_R_DHxyjaHJ1U73Y5z_May2019.csv\n",
      "SurveysMay2019/Fall2019/PRE\\Fall2019_University_of_Chicago_Department_of_Physics_131_Chantell_PRE_R_1K9lvFTu8JkcFQm_May2019.csv\n",
      "SurveysMay2019/Fall2019/PRE\\Fall2019_University_of_Chicago_Department_of_Physics_141_Chantell_PRE_R_3LYBc89FxVI4Mh0_May2019.csv\n",
      "SurveysMay2019/Fall2019/PRE\\Fall2019_University_of_Illinois_Physics_211_Selen_PRE_R_1d15J3hTqieLTa5_May2019.csv\n",
      "SurveysMay2019/Fall2019/PRE\\Fall2019_University_of_Illinois_PHYS_101_Selen_PRE_R_pLAZ8W1Xzth1JND_May2019.csv\n",
      "SurveysMay2019/Fall2019/PRE\\Fall2019_University_of_Illinois_PHYS_212_Selen_PRE_R_2uIi153R4Il8kMG_May2019.csv\n",
      "SurveysMay2019/Fall2019/PRE\\Fall2019_UNIVERSITY_OF_MAINE_PHY_121_Farooq_PRE_R_3Htp7Nwv07ZMNz5_May2019.csv\n",
      "SurveysMay2019/Fall2019/PRE\\Fall2019_University_of_Waterloo_PHYS121_Ward_PRE_R_Qg3q5z7BhK8exIB_May2019.csv\n",
      "Empty DataFrame\n",
      "Columns: [Q5a, Q5b, Q5c]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Q5a, Q5b, Q5c]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3249: DtypeWarning: Columns (33,46,75,82,95,128,142,172,192,204) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:130: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "\n",
    "Fall2019_PREValMat, Fall2019_POSTValMat = ConcatSurveys('Fall', '2019')\n",
    "\n",
    "Fall2019_PREValMat.loc[7, 'Q5c'] = 'Tamaria '\n",
    "Fall2019_POSTValMat.loc[202, 'Q5c'] = 'Connie'\n",
    "Fall2019_PREValMat.loc[534, 'Q5c'] = 'Benjamin'\n",
    "Fall2019_PREValMat.loc[711, 'Q5c'] = 'Alex'\n",
    "Fall2019_POSTValMat.loc[1082, 'Q5c'] = 'Chris'\n",
    "Fall2019_POSTValMat.loc[1095, 'Q5c'] = 'Aidi'\n",
    "Fall2019_PREValMat.loc[1336, 'Q5c'] = 'Ziyu'\n",
    "Fall2019_POSTValMat.loc[1203, 'Q5c'] = 'Jichun'\n",
    "Fall2019_PREValMat.loc[1260, 'Q5c'] = 'jeff'\n",
    "Fall2019_POSTValMat.loc[1225, 'Q5c'] = 'Ben'\n",
    "Fall2019_PREValMat.loc[1657, 'Q5c'] = 'Jonathan'\n",
    "Fall2019_PREValMat.loc[1992, 'Q5c'] = 'Parker'\n",
    "\n",
    "Fall2019_PREValMat.to_csv('Collective_Surveys/PRE_Valid_Matched/Fall2019_PRE_ValMat.csv', index = False)\n",
    "Fall2019_POSTValMat.to_csv('Collective_Surveys/POST_Valid_Matched/Fall2019_POST_ValMat.csv', index = False)\n",
    "\n",
    "Fall2019_Matched = MergeSurveys('Collective_Surveys/PRE_Valid_Matched/Fall2019_PRE_ValMat.csv',\n",
    "                                'Collective_Surveys/POST_Valid_Matched/Fall2019_POST_ValMat.csv',\n",
    "                                'Fall2019_Merged.csv')\n",
    "\n",
    "Out_Predf = Fall2019_PREValMat[~Fall2019_PREValMat['V1'].isin(Fall2019_Matched['V1_x'])]\n",
    "Out_Postdf = Fall2019_POSTValMat[~Fall2019_POSTValMat['V1'].isin(Fall2019_Matched['V1_y'])]\n",
    "\n",
    "print(Out_Predf[['Q5a', 'Q5b', 'Q5c']])\n",
    "print(Out_Postdf[['Q5a', 'Q5b', 'Q5c']])\n",
    "\n",
    "Fall2019_Complete = MergePlusMissing('Fall2019_Merged.csv', 'Fall2019_PRE_Valid.csv', 'Fall2019_POST_Valid.csv',\n",
    "                                     'Fall2019_Complete.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate all surveys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Collective_Surveys/PRE_Valid\\\\Fall2017_PRE_Valid.csv', 'Collective_Surveys/PRE_Valid\\\\Fall2018_PRE_Valid.csv', 'Collective_Surveys/PRE_Valid\\\\Fall2019_PRE_Valid.csv', 'Collective_Surveys/PRE_Valid\\\\Spring2018_PRE_Valid.csv', 'Collective_Surveys/PRE_Valid\\\\Spring2019_PRE_Valid.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:162: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Collective_Surveys/POST_Valid\\\\Fall2017_POST_Valid.csv', 'Collective_Surveys/POST_Valid\\\\Fall2018_POST_Valid.csv', 'Collective_Surveys/POST_Valid\\\\Fall2019_POST_Valid.csv', 'Collective_Surveys/POST_Valid\\\\Spring2018_POST_Valid.csv', 'Collective_Surveys/POST_Valid\\\\Spring2019_POST_Valid.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3326: DtypeWarning: Columns (214) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Collective_Surveys/PRE_Valid_Matched\\\\Fall2017_PRE_ValMat.csv', 'Collective_Surveys/PRE_Valid_Matched\\\\Fall2018_PRE_ValMat.csv', 'Collective_Surveys/PRE_Valid_Matched\\\\Fall2019_PRE_ValMat.csv', 'Collective_Surveys/PRE_Valid_Matched\\\\Spring2018_PRE_ValMat.csv', 'Collective_Surveys/PRE_Valid_Matched\\\\Spring2019_PRE_ValMat.csv']\n",
      "['Collective_Surveys/POST_Valid_Matched\\\\Fall2017_POST_ValMat.csv', 'Collective_Surveys/POST_Valid_Matched\\\\Fall2018_POST_ValMat.csv', 'Collective_Surveys/POST_Valid_Matched\\\\Fall2019_POST_ValMat.csv', 'Collective_Surveys/POST_Valid_Matched\\\\Spring2018_POST_ValMat.csv', 'Collective_Surveys/POST_Valid_Matched\\\\Spring2019_POST_ValMat.csv']\n",
      "['Collective_Surveys/Merged\\\\Fall2017_Merged.csv', 'Collective_Surveys/Merged\\\\Fall2018_Merged.csv', 'Collective_Surveys/Merged\\\\Fall2019_Merged.csv', 'Collective_Surveys/Merged\\\\Spring2018_Merged.csv', 'Collective_Surveys/Merged\\\\Spring2019_Merged.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3326: DtypeWarning: Columns (24,33,46,75,82,121,142,172,291,300,313,342,349,362,388,409,439,471) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3326: DtypeWarning: Columns (33,46,75,82,95,128,142,172,192,204) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Collective_Surveys/Complete\\\\Fall2017_Complete.csv', 'Collective_Surveys/Complete\\\\Fall2018_Complete.csv', 'Collective_Surveys/Complete\\\\Fall2019_Complete.csv', 'Collective_Surveys/Complete\\\\Spring2018_Complete.csv', 'Collective_Surveys/Complete\\\\Spring2019_Complete.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3326: DtypeWarning: Columns (0,1,2,3,24,33,46,59,75,82,95,109,121,128,139,142,161,172,182,187,188,189,192,195,204,220,254,291,300,313,342,349,362,388,395,409,439,459,471,485) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3326: DtypeWarning: Columns (33,142,313,342,349,362) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3326: DtypeWarning: Columns (4,7,15,19,30,33,47,50,63,66,78,81,96,99,102,113,117,126,145,147,150,153,165,166,167,168,171,174,183,199,258,262,263,264,265,311,324,360,373,399,406,465,470,482) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3326: DtypeWarning: Columns (0,1,2,3,24,33,46,59,75,82,95,109,121,128,139,142,161,172,182,187,188,189,192,195,204,214,218,220,254,300,313,342,349,362,409,471) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "PRE_Valid_df = CompleteConcat('PRE_Valid')\n",
    "POST_Valid_df = CompleteConcat('POST_Valid')\n",
    "PRE_ValMat_df = CompleteConcat('PRE_Valid_Matched')\n",
    "POST_ValMat_df = CompleteConcat('POST_Valid_Matched')\n",
    "Merged_df = CompleteConcat('Merged')\n",
    "Complete_df = CompleteConcat('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

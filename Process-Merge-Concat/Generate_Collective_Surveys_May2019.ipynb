{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "os.chdir('C:/Users/Cole/Documents/GitHub/PLIC-Tools/Automation-Files/')\n",
    "import Valid_Matched\n",
    "import Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup necessary files and variables for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/Cole/Documents/PLIC_DATA/')\n",
    "Weights = pd.read_excel('Weights_May2019.xlsx').transpose()[0]\n",
    "Basedf = pd.read_csv('PLIC_May2019.csv', nrows = 1)\n",
    "MainSurveys_Folder = 'SurveysMay2019/'\n",
    "Questions = ['Q1b', 'Q1d', 'Q1e', 'Q2b', 'Q2d', 'Q2e', 'Q3b', 'Q3d', 'Q3e', 'Q4b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Valid/Matched Surveys Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConcatValidSurveys(FileList, ValidLocation, ValidFileName):\n",
    "    if not os.path.exists(ValidLocation):\n",
    "        os.mkdir(ValidLocation)\n",
    "\n",
    "    dfs = []\n",
    "    for f in FileList:\n",
    "        Class_ID = 'R_' + f.split('_')[-2]\n",
    "        df = pd.read_csv(f, skiprows = [1])\n",
    "        df['Class_ID'] = Class_ID\n",
    "        df = df[(df['V5'] == 1) & (df['Unnamed: 7'] == 1) & (df['Q6d'] == 2)]\n",
    "        df = df[(df['Qt1_3'] >= 30) | (df['Qt2_3'] >= 30) | (df['Qt3_3'] >= 30) | (df['Qt4_3'] >= 30)]\n",
    "        df = df.drop_duplicates(subset = ['Q5b', 'Q5c'])\n",
    "        if('Survey' not in df.columns):\n",
    "            df['Survey'] = 'C'\n",
    "\n",
    "        Items = [c for c in df.columns for Q in Questions if Q in c and 'TEXT' not in c and 'l' not in c and '_' in c]\n",
    "        df[Items] = df[Items].fillna('0').astype(str).apply(lambda x: x.str.replace('^(?!0*$).*$', \n",
    "                                                                                    '1')).astype(float).replace(0, np.nan)\n",
    "\n",
    "        df.to_csv(ValidLocation + f.replace('\\\\', '/').split('/')[-1].split('.')[0] + '_Valid.csv', index = False)\n",
    "        dfs.append(df)\n",
    "        \n",
    "    df = pd.concat(dfs, axis = 0)\n",
    "    df.to_csv('Collective_Surveys/' + ValidFileName, index = False)\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "def ConcatMatchedSurveys(PreFileList, PostFileList, PreMatchedLocation, PostMatchedLocation, PreCollectiveSurveyName, \n",
    "                         PostCollectiveSurveyName):\n",
    "    if not os.path.exists(PreMatchedLocation):\n",
    "        os.mkdir(PreMatchedLocation)\n",
    "    if not os.path.exists(PostMatchedLocation):\n",
    "        os.mkdir(PostMatchedLocation)\n",
    "    \n",
    "    Predfs = []\n",
    "    Postdfs = []\n",
    "    for f_pre in PreFileList:\n",
    "        for f_post in PostFileList:\n",
    "            if(f_pre.split('_')[-2] != f_post.split('_')[-2]):\n",
    "                continue\n",
    "            print(f_pre)\n",
    "            Class_ID = 'R_' + f_pre.split('_')[-2] # Split of the underscore at the end for the new format\n",
    "            # Change Valid_Matched to version of matching algorithm being used\n",
    "            NPre, NPost, dfPre, dfPost = Valid_Matched.ValMat(PRE = pd.read_csv(f_pre, skiprows = [1]), \n",
    "                                                              POST = pd.read_csv(f_post, skiprows = [1]))\n",
    "            if('Survey' not in dfPre.columns):\n",
    "                dfPre['Survey'] = 'C'\n",
    "            if('Survey' not in dfPost.columns):\n",
    "                dfPost['Survey'] = 'C'\n",
    "            dfPre['Class_ID'] = Class_ID\n",
    "            dfPost['Class_ID'] = Class_ID\n",
    "            Predfs.append(dfPre)\n",
    "            Postdfs.append(dfPost)\n",
    "\n",
    "            dfPre.to_csv(PreMatchedLocation + f_pre.replace('\\\\', '/').split('/')[-1].split('.')[0] + '_ValMat.csv', \n",
    "                           index = False)\n",
    "            dfPost.to_csv(PostMatchedLocation + f_post.replace('\\\\', '/').split('/')[-1].split('.')[0] + '_ValMat.csv', \n",
    "                            index = False)\n",
    "            \n",
    "            break\n",
    "    \n",
    "    dfPre_Matched = pd.concat(Predfs, join = 'outer', axis = 0).reset_index(drop = True)\n",
    "    dfPost_Matched = pd.concat(Postdfs, join = 'outer', axis = 0).reset_index(drop = True)\n",
    "\n",
    "    dfPre_Matched.to_csv('Collective_Surveys/PRE_Valid_Matched/' + PreCollectiveSurveyName, index = False)\n",
    "    dfPost_Matched.to_csv('Collective_Surveys/POST_Valid_Matched/' + PostCollectiveSurveyName, index = False)\n",
    "\n",
    "    return(dfPre_Matched, dfPost_Matched)\n",
    "\n",
    "def ConsentAtPost(PRE_Valid_File, PRE_Valid_Matched_File):\n",
    "    Valid_df = pd.read_csv(PRE_Valid_File)\n",
    "    Matched_df = pd.read_csv(PRE_Valid_Matched_File)\n",
    "\n",
    "    # Add Pre-Surveys from matched set to overall set who enacted consent at POST\n",
    "    ActualllyValidPre = Matched_df[~Matched_df['V1'].isin(Valid_df['V1'])]\n",
    "    Total_Valid_df = pd.concat([Valid_df, ActualllyValidPre], join = 'inner', axis = 0)\n",
    "    \n",
    "    Total_Valid_df.to_csv(PRE_Valid_File, index = False)\n",
    "    \n",
    "    return(Total_Valid_df)\n",
    "\n",
    "def MergeSurveys(PRE_Matched_File, POST_Matched_File, FileName):\n",
    "    PRE_df = pd.read_csv(PRE_Matched_File)\n",
    "    POST_df = pd.read_csv(POST_Matched_File)\n",
    "    \n",
    "    PRE_df_S = Scoring.CalcScore(PRE_df, Weights)\n",
    "    POST_df_S = Scoring.CalcScore(POST_df, Weights)\n",
    "\n",
    "    PRE_df_S = PRE_df_S.rename(columns = {'TotalScores':'PreScores'})\n",
    "    POST_df_S = POST_df_S.rename(columns = {'TotalScores':'PostScores'})\n",
    "\n",
    "    PRE_df_S['FullName'] = PRE_df_S['Q5b'].str.lower().str.replace(' ', '') + PRE_df_S['Q5c'].str.lower().str.replace(' ', '')\n",
    "    POST_df_S['FullName'] = POST_df_S['Q5b'].str.lower().str.replace(' ', '') + POST_df_S['Q5c'].str.lower().str.replace(' ', '')\n",
    "    POST_df_S['BackName'] = POST_df_S['Q5c'].str.lower().str.replace(' ', '') + POST_df_S['Q5b'].str.lower().str.replace(' ', '')\n",
    "    \n",
    "    Full_df = pd.merge(left = PRE_df_S, right = POST_df_S, how = 'inner', on = ['Class_ID', 'FullName'])\n",
    "    Back_df = pd.merge(left = PRE_df_S, right = POST_df_S, how = 'inner', left_on = ['Class_ID', 'FullName'], \n",
    "                   right_on = ['Class_ID', 'BackName'])\n",
    "    ID_df = pd.merge(left = PRE_df_S, right = POST_df_S, how = 'inner', on = ['Class_ID', \n",
    "                                                                              'Q5a']).rename(columns = {'Q5a':'Q5a_x'})\n",
    "    ID_df['Q5a_y'] = ID_df['Q5a_x']\n",
    "    \n",
    "    Merged_df = pd.concat([Full_df, Back_df, ID_df], axis = 0, \n",
    "                          join = 'inner').drop_duplicates().drop(columns = ['BackName']).reset_index(drop = True)\n",
    "    \n",
    "    if('Q4b' in Merged_df.columns):\n",
    "        Merged_df = Merged_df.rename(columns = {'Q1b':'Q1b_x', 'Q1d':'Q1d_x', 'Q1e':'Q1e_x', 'Q2b':'Q2b_x', 'Q2d':'Q2d_x',\n",
    "                                                'Q2e':'Q2e_x', 'Q3b':'Q3b_x', 'Q3d':'Q3d_x', 'Q3e':'Q3e_x', 'Q4b':'Q4b_x'})\n",
    "    \n",
    "    Merged_df.to_csv('Collective_Surveys/Merged/' + FileName, index = False)\n",
    "    \n",
    "    return(Merged_df)\n",
    "\n",
    "def MergePlusMissing(MergedFile, ValidPRE_File, ValidPOST_File, CompleteFileName):\n",
    "    \n",
    "    Merged_df = pd.read_csv('Collective_Surveys/Merged/' + MergedFile)\n",
    "\n",
    "    PRE_df = pd.read_csv('Collective_Surveys/PRE_Valid/' + ValidPRE_File)\n",
    "    POST_df = pd.read_csv('Collective_Surveys/POST_Valid/' + ValidPOST_File)\n",
    "\n",
    "    PRE_df_S = Scoring.CalcScore(PRE_df, Weights).rename(columns = {'TotalScores':'PreScores'})\n",
    "    POST_df_S = Scoring.CalcScore(POST_df, Weights).rename(columns = {'TotalScores':'PostScores'})\n",
    "\n",
    "    Unmatched_PRE = PRE_df_S[~PRE_df_S['V1'].isin(Merged_df['V1_x'])]\n",
    "    Unmatched_POST = POST_df_S[~POST_df_S['V1'].isin(Merged_df['V1_y'])]\n",
    "\n",
    "    Unmatched_PRE.columns = [c + '_x' if c != 'Class_ID' and c != 'PreScores' else c for c in Unmatched_PRE.columns]\n",
    "    Unmatched_POST.columns = [c + '_y' if c != 'Class_ID' and c != 'PostScores' else c for c in Unmatched_POST.columns]\n",
    "\n",
    "    Complete_df = pd.concat([Merged_df, Unmatched_PRE, Unmatched_POST], axis = 0, join = 'outer')\n",
    "    Complete_df = Complete_df[Merged_df.columns]\n",
    "    Complete_df.to_csv('Collective_Surveys/Complete/' + CompleteFileName, index = False)\n",
    "\n",
    "    return(Complete_df)\n",
    "\n",
    "def ConcatSurveys(Semester, Year):\n",
    "    PreFiles = glob(MainSurveys_Folder + Semester + Year + '/PRE/*.csv')\n",
    "    PostFiles = glob(MainSurveys_Folder + Semester + Year + '/POST/*.csv')\n",
    "\n",
    "    PREValid = ConcatValidSurveys(PreFiles, MainSurveys_Folder + Semester + Year + '/PRE/Valid/',\n",
    "                                  'PRE_Valid/' + Semester + Year + '_PRE_Valid.csv')\n",
    "    POSTValid = ConcatValidSurveys(PostFiles, MainSurveys_Folder + Semester + Year + '/POST/Valid/',\n",
    "                                   'POST_Valid/' + Semester + Year + '_POST_Valid.csv')\n",
    "\n",
    "    PREValMat, POSTValMat = ConcatMatchedSurveys(PreFiles, PostFiles,\n",
    "                                                 MainSurveys_Folder + Semester + Year + '/PRE/Valid/Matched/',\n",
    "                                                 MainSurveys_Folder + Semester + Year + '/POST/Valid/Matched/',\n",
    "                                                 Semester + Year + '_PRE_ValMat.csv',\n",
    "                                                 Semester + Year + '_POST_ValMat.csv')\n",
    "\n",
    "    PREValid = ConsentAtPost('Collective_Surveys/PRE_Valid/' + Semester + Year + '_PRE_Valid.csv',\n",
    "                             'Collective_Surveys/PRE_Valid_Matched/' + Semester + Year + '_PRE_ValMat.csv')\n",
    "    \n",
    "    return(PREValMat, POSTValMat)\n",
    "\n",
    "def CompleteConcat(FolderName):\n",
    "    Files = [f for f in glob('Collective_Surveys/' + FolderName + '/*') if 'Concat' not in f]\n",
    "    \n",
    "    print(Files)\n",
    "    \n",
    "    dfs = [pd.read_csv(f) for f in Files]\n",
    "    df = pd.concat(dfs, join = 'outer', axis = 0)\n",
    "    df.to_csv('Collective_Surveys/' + FolderName + '/' + FolderName + '_Concat.csv', index = False)\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate Fall 2017 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "Fall2017_PREValMat, Fall2017_POSTValMat = ConcatSurveys('Fall', '2017')\n",
    "\n",
    "Fall2017_POSTValMat.loc[86, 'Q5c'] = 'Chris'\n",
    "Fall2017_POSTValMat.loc[124, 'Q5c'] = 'Will'\n",
    "Fall2017_PREValMat.loc[242, 'Q5c'] = 'Ray'\n",
    "Fall2017_PREValMat.loc[270, 'Q5c'] = 'Chris'\n",
    "Fall2017_PREValMat.loc[195, 'Q5c'] = 'Ben'\n",
    "Fall2017_POSTValMat.loc[228, 'Q5c'] = 'Theo'\n",
    "Fall2017_POSTValMat.loc[320, 'Q5c'] = 'Santi'\n",
    "Fall2017_POSTValMat.loc[347, 'Q5c'] = 'Zac'\n",
    "Fall2017_PREValMat.loc[417, 'Q5b'] = 'StLouis'\n",
    "Fall2017_POSTValMat.loc[509, 'Q5c'] = 'Omar'\n",
    "Fall2017_POSTValMat.loc[529, 'Q5c'] = 'Brad'\n",
    "\n",
    "Fall2017_PREValMat.to_csv('Collective_Surveys/PRE_Valid_Matched/Fall2017_PRE_ValMat.csv', index = False)\n",
    "Fall2017_POSTValMat.to_csv('Collective_Surveys/POST_Valid_Matched/Fall2017_POST_ValMat.csv', index = False)\n",
    "\n",
    "Fall2017_Matched = MergeSurveys('Collective_Surveys/PRE_Valid_Matched/Fall2017_PRE_ValMat.csv',\n",
    "                                'Collective_Surveys/POST_Valid_Matched/Fall2017_POST_ValMat.csv',\n",
    "                                'Fall2017_Merged.csv')\n",
    "\n",
    "Fall2017_Complete = MergePlusMissing('Fall2017_Merged.csv', 'Fall2017_PRE_Valid.csv', 'Fall2017_POST_Valid.csv', \n",
    "                                     'Fall2017_Complete.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate Spring 2018 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "Spring2018_PREValMat, Spring2018_POSTValMat = ConcatSurveys('Spring', '2018')\n",
    "\n",
    "Spring2018_PREValMat.loc[8, 'Q5c'] = 'Joshua'\n",
    "Spring2018_PREValMat.loc[12, 'Q5c'] = 'Daria'\n",
    "Spring2018_POSTValMat.loc[5, 'Q5c'] = 'Greg'\n",
    "Spring2018_POSTValMat.loc[148, 'Q5c'] = 'Edward'\n",
    "Spring2018_PREValMat.loc[388, 'Q5c'] = 'Mourud'\n",
    "\n",
    "Spring2018_PREValMat.to_csv('Collective_Surveys/PRE_Valid_Matched/Spring2018_PRE_ValMat.csv', index = False)\n",
    "Spring2018_POSTValMat.to_csv('Collective_Surveys/POST_Valid_Matched/Spring2018_POST_ValMat.csv', index = False)\n",
    "\n",
    "Spring2018_Matched = MergeSurveys('Collective_Surveys/PRE_Valid_Matched/Spring2018_PRE_ValMat.csv', \n",
    "                                  'Collective_Surveys/POST_Valid_Matched/Spring2018_POST_ValMat.csv',\n",
    "                                  'Spring2018_Merged.csv')\n",
    "\n",
    "Spring2018_Complete = MergePlusMissing('Spring2018_Merged.csv', 'Spring2018_PRE_Valid.csv', 'Spring2018_POST_Valid.csv',\n",
    "                                       'Spring2018_Complete.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate Fall 2018 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "Fall2018_PREValMat, Fall2018_POSTValMat = ConcatSurveys('Fall', '2018')\n",
    "\n",
    "Fall2018_PREValMat.loc[8, 'Q5c'] = 'Alex'\n",
    "Fall2018_POSTValMat.loc[50, 'Q5c'] = 'Alex'\n",
    "Fall2018_PREValMat.loc[280, 'Q5a'] = '900725834'\n",
    "Fall2018_PREValMat.loc[380, 'Q5c'] = 'Chris'\n",
    "Fall2018_POSTValMat.loc[581, 'Q5c'] = 'Christopher'\n",
    "Fall2018_PREValMat.loc[606, 'Q5c'] = 'Cece'\n",
    "Fall2018_PREValMat.loc[716, 'Q5c'] = 'Ben'\n",
    "Fall2018_POSTValMat.loc[737, 'Q5c'] = 'Sam'\n",
    "Fall2018_POSTValMat.loc[730, 'Q5c'] = 'Rob'\n",
    "Fall2018_PREValMat.loc[1042, 'Q5c'] = 'Kamsi'\n",
    "Fall2018_POSTValMat.loc[1028, 'Q5c'] = 'Alex'\n",
    "Fall2018_POSTValMat.loc[1054, 'Q5c'] = 'Tiffany'\n",
    "Fall2018_POSTValMat.loc[1167, 'Q5c'] = 'Alex'\n",
    "\n",
    "Fall2018_PREValMat.to_csv('Collective_Surveys/PRE_Valid_Matched/Fall2018_PRE_ValMat.csv', index = False)\n",
    "Fall2018_POSTValMat.to_csv('Collective_Surveys/POST_Valid_Matched/Fall2018_POST_ValMat.csv', index = False)\n",
    "\n",
    "Fall2018_Matched = MergeSurveys('Collective_Surveys/PRE_Valid_Matched/Fall2018_PRE_ValMat.csv', \n",
    "                                'Collective_Surveys/POST_Valid_Matched/Fall2018_POST_ValMat.csv',\n",
    "                                'Fall2018_Merged.csv')\n",
    "\n",
    "Fall2018_Complete = MergePlusMissing('Fall2018_Merged.csv', 'Fall2018_PRE_Valid.csv', 'Fall2018_POST_Valid.csv',\n",
    "                                     'Fall2018_Complete.csv')\n",
    "\n",
    "Out_Predf = Fall2018_PREValMat[~Fall2018_PREValMat['V1'].isin(Fall2018_Matched['V1_x'])]\n",
    "Out_Postdf = Fall2018_POSTValMat[~Fall2018_POSTValMat['V1'].isin(Fall2018_Matched['V1_y'])]\n",
    "\n",
    "print(Out_Predf[['Q5a', 'Q5b', 'Q5c']])\n",
    "print(Out_Postdf[['Q5a', 'Q5b', 'Q5c']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate Spring 2019 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "Spring2019_PREValMat, Spring2019_POSTValMat = ConcatSurveys('Spring', '2019')\n",
    "\n",
    "Spring2019_POSTValMat.loc[27, 'Q5b'] = 'Rocha'\n",
    "Spring2019_POSTValMat.loc[115, 'Q5c'] = 'Alex'\n",
    "Spring2019_PREValMat.loc[131, 'Q5c'] = 'Zach'\n",
    "Spring2019_PREValMat.loc[194, 'Q5c'] = 'Josh' \n",
    "Spring2019_PREValMat.loc[651, 'Q5c'] = 'Tim'\n",
    "Spring2019_POSTValMat.loc[705, 'Q5c'] = 'Josh'\n",
    "\n",
    "Spring2019_PREValMat.to_csv('Collective_Surveys/PRE_Valid_Matched/Spring2019_PRE_ValMat.csv', index = False)\n",
    "Spring2019_POSTValMat.to_csv('Collective_Surveys/POST_Valid_Matched/Spring2019_POST_ValMat.csv', index = False)\n",
    "\n",
    "Spring2019_Matched = MergeSurveys('Collective_Surveys/PRE_Valid_Matched/Spring2019_PRE_ValMat.csv', \n",
    "                                'Collective_Surveys/POST_Valid_Matched/Spring2019_POST_ValMat.csv',\n",
    "                                'Spring2019_Merged.csv')\n",
    "\n",
    "Out_Predf = Spring2019_PREValMat[~Spring2019_PREValMat['V1'].isin(Spring2019_Matched['V1_x'])]\n",
    "Out_Postdf = Spring2019_POSTValMat[~Spring2019_POSTValMat['V1'].isin(Spring2019_Matched['V1_y'])]\n",
    "\n",
    "print(Out_Predf[['Q5a', 'Q5b', 'Q5c']])\n",
    "print(Out_Postdf[['Q5a', 'Q5b', 'Q5c']])\n",
    "\n",
    "Spring2019_Complete = MergePlusMissing('Spring2019_Merged.csv', 'Spring2019_PRE_Valid.csv', 'Spring2019_POST_Valid.csv',\n",
    "                                       'Spring2019_Complete.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate Fall 2019 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PreFiles = glob(MainSurveys_Folder + 'Fall' + '2019' + '/PRE/*.csv')\n",
    "\n",
    "PREValid = ConcatValidSurveys(PreFiles, MainSurveys_Folder + 'Fall' + '2019' + '/PRE/Valid/',\n",
    "                                  'PRE_Valid/' + 'Fall' + '2019' + '_PRE_Valid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate all surveys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Collective_Surveys/PRE_Valid\\\\Fall2017_PRE_Valid.csv', 'Collective_Surveys/PRE_Valid\\\\Fall2018_PRE_Valid.csv', 'Collective_Surveys/PRE_Valid\\\\Fall2019_PRE_Valid.csv', 'Collective_Surveys/PRE_Valid\\\\Spring2018_PRE_Valid.csv', 'Collective_Surveys/PRE_Valid\\\\Spring2019_PRE_Valid.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2961: DtypeWarning: Columns (95) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:162: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Collective_Surveys/POST_Valid\\\\Fall2017_POST_Valid.csv', 'Collective_Surveys/POST_Valid\\\\Fall2018_POST_Valid.csv', 'Collective_Surveys/POST_Valid\\\\Spring2018_POST_Valid.csv', 'Collective_Surveys/POST_Valid\\\\Spring2019_POST_Valid.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2961: DtypeWarning: Columns (214) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Collective_Surveys/PRE_Valid_Matched\\\\Fall2017_PRE_ValMat.csv', 'Collective_Surveys/PRE_Valid_Matched\\\\Fall2018_PRE_ValMat.csv', 'Collective_Surveys/PRE_Valid_Matched\\\\Spring2018_PRE_ValMat.csv', 'Collective_Surveys/PRE_Valid_Matched\\\\Spring2019_PRE_ValMat.csv']\n",
      "['Collective_Surveys/POST_Valid_Matched\\\\Fall2017_POST_ValMat.csv', 'Collective_Surveys/POST_Valid_Matched\\\\Fall2018_POST_ValMat.csv', 'Collective_Surveys/POST_Valid_Matched\\\\Spring2018_POST_ValMat.csv', 'Collective_Surveys/POST_Valid_Matched\\\\Spring2019_POST_ValMat.csv']\n",
      "['Collective_Surveys/Merged\\\\Fall2017_Merged.csv', 'Collective_Surveys/Merged\\\\Fall2018_Merged.csv', 'Collective_Surveys/Merged\\\\Spring2018_Merged.csv', 'Collective_Surveys/Merged\\\\Spring2019_Merged.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2961: DtypeWarning: Columns (24,33,46,75,82,121,142,172,291,300,313,342,349,362,388,409,439,471) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Collective_Surveys/Complete\\\\Fall2017_Complete.csv', 'Collective_Surveys/Complete\\\\Fall2018_Complete.csv', 'Collective_Surveys/Complete\\\\Spring2018_Complete.csv', 'Collective_Surveys/Complete\\\\Spring2019_Complete.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2961: DtypeWarning: Columns (0,1,2,3,24,33,46,59,75,82,95,109,121,128,139,142,161,172,182,187,188,189,192,195,204,220,254,291,300,313,342,349,362,388,395,409,439,459,471,485) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2961: DtypeWarning: Columns (4,7,15,19,30,33,47,50,63,66,78,81,96,99,102,113,117,126,145,147,150,153,165,166,167,168,171,174,183,199,258,262,263,264,265,311,324,360,373,399,406,465,470,482) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2961: DtypeWarning: Columns (0,1,2,3,24,33,46,59,75,82,95,109,121,128,139,142,161,172,182,187,188,189,192,195,204,214,218,220,254,300,313,342,349,362,409,471) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "PRE_Valid_df = CompleteConcat('PRE_Valid')\n",
    "POST_Valid_df = CompleteConcat('POST_Valid')\n",
    "PRE_ValMat_df = CompleteConcat('PRE_Valid_Matched')\n",
    "POST_ValMat_df = CompleteConcat('POST_Valid_Matched')\n",
    "Merged_df = CompleteConcat('Merged')\n",
    "Complete_df = CompleteConcat('Complete')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

---
output:
  pdf_document: default
  html_document: default
#title: 'AB Analysis'
#runtime: shiny
---

```{r global_options, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{r}
source('SLIC_AB_wrangling.R')
df.students <- read.csv('AB_analysis_data.csv')
```

```{r, include = FALSE}
library(plyr)
library(MASS)
library(readr)
library(tidyverse)
library(ryouready)
library(nnet)
library(ggthemes)
library(reshape2)
library(ggstatsplot)
library(MRCV)
library(DescTools)
library(plotly)
library(lmerTest)
library(survival)
library(survminer)
library(gridExtra)
library(ggpubr)
source('PLIC_DataProcessing.R')
theme_set(theme_classic(base_size = 12))
palette.4 <- c('#9F0162', '#009F81', '#008DF9', '#FF6E3A')
palette.4_2 <- c('#8400CD', '#FF5AAF', '#E20134', '#00C2F9')
palette.2_1 <- c('#00C2F9', '#A40122')
palette.2_2 <- c('#B400CD', '#FFC33B')
palette.2_3 <- c('#E20134', '#008607')
```


```{r, eval = FALSE}
make.master.PLIC("C:/Users/Cole/Documents/DATA/PLIC_DATA/SurveysNovember2020/")
```
There are about 400 students in each of the four conditions, which is a good number. That should provide enough power for what we want to do.

```{r}
df.students <- read.csv('AB_analysis_data.csv')
# text from rows beneath header
info <- data.frame(lapply(read.csv('PLIC_November2020.csv', nrows = 1), 
                          FUN = function(x) gsub("^.*- ", "", x)))

print('# of students by condition')
table(df.students$Condition)

print('# of unique classes')
length(unique(df.students$Class.ID))

print('# of unique schools')
length(unique(df.students$School))
```

```{r}
Likert.comparison.items <- list(list('Q139_1', 'Q2d_1', 'Q152_1', 
                                     'Equipment used'),
                                list('Q139_2', 'Q2d_2', 'Q152_2', 
                                     'Variables measured'),
                                list('Q139_3', 'Q2d_3', 'Q152_3', 
                                     'Variables controlled'),
                                list('Q140_1', 'Q142_1', 'Q153_1', 'N trials'),
                                list('Q140_2', 'Q142_2', 'Q153_2', 'N masses'),
                                list('Q140_3', 'Q142_3', 'Q153_3', 'N bounces'),
                                list('Q141_1', 'Q157_1', 'Q154_1', 
                                     'Explanations'),
                                list('Q141_2', 'Q157_2', 'Q154_2', 'Analysis'),
                                list('Q141_3', 'Q157_3', 'Q154_3', 
                                     'Similar k values'),
                                list('Q141_4', 'Q157_4', 'Q154_4', 
                                     'Uncertainty in data'))

df <- df.students %>%
  mutate(Condition = case_when(
    Condition %like% 'Likert' ~ 'Likert',
    TRUE ~ 'No Likert'
    ))

quilt.plot(df, Likert.comparison.items, legend = TRUE, 
           type = 'aggregate', palette = colorRampPalette(c('white', 'red')), 
           scale = 'full', margin = c(2, 8, 0, 0))

quilt.plot(df, Likert.comparison.items, Condition = 'Condition', legend = TRUE, 
           type = 'hatched', palette = colorRampPalette(c('white', 'red')), 
           panels = 'Comparison', panel.labels = "Comparison of the groups' methods", 
           scale = 'full', margin = c(2, 8, 0, 0))

quilt.plot(df, Likert.comparison.items, Condition = 'Condition', legend = TRUE, 
           type = 'difference', palette = colorRampPalette(c('blue', 'white', 'red')), 
           panels = 'Comparison', panel.labels = "Comparison of the groups' methods", 
           scale = c(-0.25, 0.25), 
           legend.extremes = c('Likert\nlarger', 'No Likert\nlarger'))

quilt.plot(df, Likert.comparison.items, Condition = 'Condition', legend = TRUE, 
           type = 'side-by-side', palette = colorRampPalette(c('white', 'red')), 
           panels = 'Comparison', scale = 'full', margin = c(2, 8, 0, 0))


quilt.plot(df.students %>%
             filter(Condition %like% 'Likert') %>%
             mutate(Condition = case_when(
               Condition %like% '-1' ~ '1->2',
               TRUE ~ '2->1'
               )), Likert.comparison.items, Condition = 'Condition', legend = TRUE, 
           type = 'hatched', palette = colorRampPalette(c('white', 'red')), 
           panels = c('Group.1', 'Group.2', 'Comparison'), 
           panel.labels = c("Characterization of\nGroup 1's methods", 
                            "Characterization of\nGroup 2's methods", 
                            "Comparison of the\ngroups' methods"), scale = 'full')
```

# Analysis
```{r, message = FALSE, warning = FALSE, eval = FALSE}
print('Class standing X Condition')
table(df.students$Class.standing, df.students$Condition)
chisq.test(df.students$Class.standing, df.students$Condition)

print('Major X Condition')
table(df.students$Major, df.students$Condition)
chisq.test(df.students$Major, df.students$Condition)

print('Gender X Condition')
table(df.students$Gender, df.students$Condition)
chisq.test(df.students$Gender, df.students$Condition)

print('Race/ethnicity X Condition')
df.students$Lab_purpose <- df.students$Condition
Race.ethnicity.table(df.students, Lab.Purpose = TRUE, normalize = FALSE)

set.seed(11)
df.race <- df.students[, c('Condition', 
                           names(df.students)[names(df.students) %like% 
                                                'Race.ethnicity'])]
df.race[is.na(df.race)] <- 0
MI.test(df.race[, 1:(ncol(df.race) - 1)], I = 1, J = ncol(df.race) - 2, B = 1000, 
        print.status = FALSE)

print('Course level X Condition')
table(df.students$Course.Level, df.students$Condition)
chisq.test(df.students$Course.Level, df.students$Condition)
```
Randomization looks to have done its job. There aren't any glaring cases of over/under-representations in any of the conditions. I think class standing/course level/major are the most important things to pay attention to here. I don't have any reasons to think students responses would vary by gender and or race/ethnicity and bias our results. But, regardless, the conditions are balanced along these lines as well.

## Who did a better job?

I start with the multiple choice summary item that asks respondents who they thought did a better job of testing the model?

### All four conditions
```{r, warning = FALSE, message = FALSE, echo = FALSE}
df.students[, 'Q4a'] <- as.factor(df.students[, 'Q4a'])
df.students <- recode2(df.students, vars = 'Q4a', 
                       recodes = "1 = '1'; 2 = '2'; 3 = 'B'; 4 = 'N'")
p <- ggplot(filter(df.students, !is.na(Q4a)), aes(x = Q4a, fill = Condition, 
                                                  group = Condition)) +
    geom_bar(position = 'dodge', aes(y = ..prop..)) +
    labs(fill = 'Condition', x = 'Selection', y = 'Fraction of respondents') +
    scale_fill_manual(labels = c('Group 1 first (Likert)', 
                                   'Group 2 first (Likert)', 
                                   'Group 1 first (No Likert)', 
                                   'Group 2 first (No Likert)'), 
                        values = palette.4) +
    scale_x_discrete(labels = c('Group 1', 'Group 2', 
                                'Both were\nhighly effective', 
                                'Both were\nminimally effective'))
ggplotly(p)

df.students <- df.students %>% 
  mutate(Likert = 1 * grepl('Likert', df.students$Condition),
         G2.First = 1 * grepl('2', df.students$Condition))
```

```{r, eval = FALSE}
chisq.test(df.students$Condition, df.students$Q4a)
chisq.test(df.students$Likert, df.students$Q4a)
chisq.test(df.students$G2.First, df.students$Q4a)
```

Beginning with the summary item (Q4a: Which group do you think did a better job?), we fail to reject the null hypothesis (at alpha = 0.05) that the distribution of selections differ by condition. There are some trends: students are more likely to select the group they saw last as having done a better job. This effect isn't super big, obviously, and there's more on the effect size below.

### Order/Likert

Below, I look at the raw percentages by the Likert and ordering conditions separately without any modeling.
```{r}
p <- ggplot(filter(df.students, !is.na(Q4a)), aes(x = Q4a, 
                                                  fill = factor(Likert))) +
    geom_bar(position = 'dodge', aes(y = ..prop.., group = factor(Likert))) +
    labs(fill = '', x = 'Selection', 
         y = 'Fraction of respondents') +
  scale_fill_manual(labels = c('No Likert', 'Likert'), values = palette.2_1) +
  scale_x_discrete(labels = c('Group 1', 'Group 2', 'Both were\nhighly effective', 
                              'Both were\nminimally effective'))
p <- plotly_build(p)
p$x$data[[1]]$name <- 'No Likert'
p$x$data[[2]]$name <- 'Likert'
ggplotly(p) %>% 
  layout(legend = list(x = 0.9, y = 1, title = list(text = 'Likert items?')))

p <- ggplot(filter(df.students, !is.na(Q4a)), aes(x = Q4a, 
                                                  fill = factor(G2.First))) +
    geom_bar(position = 'dodge', aes(y = ..prop.., group = factor(G2.First))) +
    labs(fill = '', x = 'Selection', y = 'Fraction of respondents') +
  scale_fill_manual(labels = c('1','2'), values = palette.2_2) +
  scale_x_discrete(labels = c('Group 1', 'Group 2', 'Both were\nhighly effective', 
                              'Both were\nminimally effective'))
p <- plotly_build(p)
p$x$data[[1]]$name <- '1'
p$x$data[[2]]$name <- '2'
ggplotly(p) %>% 
  layout(legend = list(x = 0.9, y = 1, title = list(text = 'Group shown first')))
```
Likert items have essentially no effect. Group ordering has maybe an effect of 3-5 percentage points --- small anyway.

### Multinomial model of "Who did better?"
```{r, warning = FALSE, message = FALSE, echo = FALSE}
# we'll use 'Both' as the base level throughout because its neutral and more common
# than 'Neither' increasing precision
df.students$Q4a <- relevel(df.students$Q4a, ref = 'B')
model <- multinom(Q4a ~ Likert + G2.First, df.students)
p <- ggcoefstats(model, output = 'tidy', exponentiate = TRUE) %>%
  filter(!grepl('Intercept', term)) %>% # we don't care about the intercepts
  mutate(term = gsub('G2.First', 'Group 2 first', term),
         term = gsub('Likert', 'Scaffolding', term),
         term = gsub('_N', ' (Neither group/Both groups)', term),
         term = gsub('_2', ' (Group 2/Both groups)', term),
         term = gsub('_1', ' (Group 1/Both groups)', term)) %>%
  arrange(desc(term)) %>%
  ggcoefstats(., vline = FALSE) +
  labs(x = 'Change in odds ratio', y = 'Effect', 
       title = 'Which group did a better job?') +
  geom_vline(xintercept = 1, linetype = 'dashed')
ggplotly(p)
```
This multinomial model illustrates the independent effects for Q4a. Showing the Likert items in the survey has little to no effect on students' responses to Q4a. Group ordering may have a small effect, with a greater proportion of students selecting "Group 1"" and "neither group" when shown Group 2 first. 

We cannot reject that any of these coefficients are different from zero and that our observations couldn't haven't been produced by random chance with a high degree of certainty. At the very least, we can put a bound on the effect on group ordering --- with 95% confidence, the change in log odds of Group 1/Both groups is smaller than about 0.5.

#### Group comparison questions
```{r}
Questions <- c('Q152_1',	'Q152_2', 'Q152_3',	'Q152_4', 'Q153_1', 'Q153_2', 
               'Q153_3', 'Q154_1', 'Q154_2', 'Q154_3', 'Q154_4')

# need to recode questions, throughout Group 1 is synonymous with Team Panda and
# Group 2 is synonymous with Team Ostrich
df.comparison <- recode2(df.students, vars = Questions, 
                       recodes = "1 = '1'; 2 = '2'; 3 = 'B'; 4 = 'N'") %>%
  mutate(Condition = str_replace(Condition, '-', '_')) %>%
  melt(., id.vars = 'Condition', measure.vars = Questions) %>%
  group_by(Condition, variable, value) %>%
  summarize(N = n()) %>%
  data.table(.)
df.comparison <- df.comparison[, Total := sum(N), 
                       by = c('Condition', 'variable')][, Frac := N/Total] %>%
  data.frame(.) %>%
  select(Condition, variable, value, Frac) %>%
  filter(!is.na(value))
df.comparison <- dcast(df.comparison, variable + value ~ Condition, 
                       value.var = 'Frac')

fig <- plot_ly(df.comparison[df.comparison$variable == Questions[1],], 
               type = 'bar', x = ~value, y = ~Likert_1, name = 'Likert-1', 
               color = I(palette.4[1])) %>% 
  add_trace(y = ~Likert_2, name = 'Likert-2', color = I(palette.4[2])) %>%
  add_trace(y = ~None_1, name = 'None-1', color = I(palette.4[3])) %>%
  add_trace(y = ~None_2, name = 'None-2', color = I(palette.4[4]))

for(Q in Questions[-1]){
  fig <- fig %>% add_trace(data = df.comparison[df.comparison$variable == Q,],
                           y = ~Likert_1, name = 'Likert-1', 
                           color = I(palette.4[1]), visible = FALSE) %>% 
    add_trace(data = df.comparison[df.comparison$variable == Q,], y = ~Likert_2, 
              name = 'Likert-2', color = I(palette.4[2]), visible = FALSE) %>% 
    add_trace(data = df.comparison[df.comparison$variable == Q,], y = ~None_1, 
              name = 'None-1', color = I(palette.4[3]), visible = FALSE) %>% 
    add_trace(data = df.comparison[df.comparison$variable == Q,], y = ~None_2, 
              name = 'None-2', color = I(palette.4[4]), visible = FALSE)
}

fig <- fig %>%
  layout(barmode = 'group',
         xaxis = list(title = 'Selection'),
         yaxis = list(title = 'Fraction of respondents'),
         updatemenus = list(
           list(
             x = 0.75,
             y = 1.1,
             buttons = lapply(Questions, function(Q){
               list(method = 'restyle',
                    args = list('visible', df.comparison$variable == Q),
                    label = strsplit(info[1, Q], ':')[[1]][1])
             })
           )
         ))
fig
```

## Likert items
```{r}
Questions <- c('Q139_1', 'Q139_2', 'Q139_3', 'Q140_1', 'Q140_2', 'Q140_3', 
               'Q141_1', 'Q141_2', 'Q141_3',	'Q141_4', 'Q2d_1', 'Q2d_2', 
               'Q2d_3', 'Q142_1', 'Q142_2', 'Q142_3', 'Q157_1', 'Q157_2', 
               'Q157_3', 'Q157_4')

df.Likert <- df.students %>%
  mutate(Condition = str_replace(Condition, '-', '_')) %>%
  filter(Condition == 'Likert_1' | Condition == 'Likert_2') %>%
  melt(., id.vars = 'G2.First', measure.vars = Questions) %>%
  group_by(G2.First, variable, value) %>%
  summarize(N = n()) %>%
  data.table(.)
df.Likert <- df.Likert[, Total := sum(N), 
                       by = c('G2.First', 'variable')][, Frac := N/Total] %>%
  data.frame(.) %>%
  select(G2.First, variable, value, Frac) %>%
  filter(!is.na(value))
df.Likert <- dcast(df.Likert, variable + value ~ G2.First, value.var = 'Frac')
colnames(df.Likert) <- c('variable', 'value', 'Group_1', 'Group_2')

fig <- plot_ly(df.Likert[df.Likert$variable == Questions[1],], 
               type = 'bar', x = ~value, y = ~Group_1, name = 'Group 1 first', 
               color = I(palette.2_2[1])) %>% 
  add_trace(y = ~Group_2, name = 'Group 2 first', color = I(palette.2_2[2]))
for(Q in Questions[-1]){
  fig <- fig %>% add_trace(data = df.Likert[df.Likert$variable == Q,],
                           y = ~Group_1, name = 'Group 1 first', 
                           color = I(palette.2_2[1]), visible = FALSE) %>% 
    add_trace(data = df.Likert[df.Likert$variable == Q,], y = ~Group_2, 
              name = 'Group 2 first', color = I(palette.2_2[2]), visible = FALSE)
}

fig <- fig %>%
  layout(barmode = 'group',
         xaxis = list(title = 'Selection'),
         yaxis = list(title = 'Fraction of respondents'),
         updatemenus = list(
           list(
             x = 1.1,
             y = 1.1,
             buttons = lapply(Questions, function(Q){
               list(method = 'restyle',
                    args = list('visible', c(rbind(Questions == Q, 
                                                   Questions == Q))),
                    label = paste(ifelse(grepl('Q139|Q140|Q141', Q), 
                                         'Group 1:', 'Group 2:'), 
                                  strsplit(info[1, Q], ':')[[1]][1]))
             })
           )
         ))
fig
```

```{r}
Likert.comparison.items <- list(list('Q139_1', 'Q2d_1', 'Q152_1', 
                                     'Equipment used'),
                                list('Q139_2', 'Q2d_2', 'Q152_2', 
                                     'Variables measured'),
                                list('Q139_3', 'Q2d_3', 'Q152_3', 
                                     'Variables controlled'),
                                list('Q140_1', 'Q142_1', 'Q153_1', 'N trials'),
                                list('Q140_2', 'Q142_2', 'Q153_2', 'N masses'),
                                list('Q140_3', 'Q142_3', 'Q153_3', 'N bounces'),
                                list('Q141_1', 'Q157_1', 'Q154_1', 
                                     'Explanations'),
                                list('Q141_2', 'Q157_2', 'Q154_2', 'Analysis'),
                                list('Q141_3', 'Q157_3', 'Q154_3', 
                                     'Similar k values'),
                                list('Q141_4', 'Q157_4', 'Q154_4', 
                                     'Uncertainty in data'))

quilt.plot(df.students %>%
             filter(Condition %like% 'Likert') %>%
             mutate(Condition = case_when(
               Condition == 'Likert-1' ~ '1->2',
               Condition == 'Likert-2' ~ '2->1',
               TRUE ~ Condition
             )), Likert.comparison.items, Condition = 'Condition', 
           palette = colorRampPalette(c("white", "#B31B1B")), PLIC = FALSE, legend = TRUE)
```

```{r, eval = FALSE}
df.Likert.test <- df.students %>%
  filter(Condition == 'Likert-1' | Condition == 'Likert-2') %>%
  dplyr::select(any_of(c('G2.First', Questions))) %>%
  mutate(student = 1:nrow(.)) %>%
  melt(., id.vars = c('G2.First', 'student')) %>%
  mutate(CC.avail = case_when(
    (G2.First == 0) & (variable %like% '2d|142|157') ~ 1,
    (G2.First == 1) & (variable %like% '139|140|141') ~ 1,
    TRUE ~ 0
  )) %>%
  select(CC.avail, variable, value)

get.coef.se <- function(df, Q){
  mod <- clm(factor(value) ~ CC.avail, data = subset(df, variable == Q))
  coefs <- summary(mod)$coefficients['CC.avail', ]
  return(list(coefs['Estimate'], coefs['Std. Error']))
}

coefs <- rbindlist(lapply(Questions, get.coef.se, df = df.Likert.test)) %>%
  `colnames<-`(c('estimate', 'se')) %>%
  mutate(term = Questions,
         conf.low = exp(estimate - 1.96 * se),
         conf.high = exp(estimate + 1.96 * se),
         estimate = exp(estimate))

info.t <- data.frame(t(info)) %>%
  `colnames<-`('Text')
info.t$index <- row.names(info.t)
coefs <- left_join(coefs, info.t, by = c('term' = 'index')) %>%
  mutate(Text = ifelse(term %like% 'Q139|Q140|Q141', 
                       paste('Group 1:', Text, sep = ' '),  
                       paste('Group 2:', Text, sep = ' ')))

p <- ggplot(coefs, aes(x = reorder(term, -estimate), y = estimate, text = Text)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0) +
  labs(x = 'Item', y = 'Change in odds ratio', 
       title = 'Effect of having a contrasting case present of\nthinking the group did a better job') +
  geom_hline(yintercept = 1, linetype = 'dashed') +
  coord_flip() +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank())
ggplotly(p)
```
**Questions 2 and 3 from email thread**

*We would need to decide on benefits and drawbacks before answering question 2.*

I think question 3 is interesting given the results below for the *what next* items. Given that students key in methods to rectify sample size issues in those items and students' answers depend on whether they see a contrasting case, I think its interesting whether they responded similarly to Likert items that ask about sample size issues.

Interestingly, responses to the Likert items **do not** seem to depend on whether students saw a contrasting case, looking particularly at components of the methods related to the number of trials and masses.

### Likert items vs. comparison items (i.e., consistency?)
```{r}
Likert.comparison.items <- list(list('Q139_1', 'Q2d_1', 'Q152_1', 
                                     'Equipment used'),
                                list('Q139_2', 'Q2d_2', 'Q152_2', 
                                     'Variables measured'),
                                list('Q139_3', 'Q2d_3', 'Q152_3', 
                                     'Variables controlled'),
                                list('Q140_1', 'Q142_1', 'Q153_1', 'N trials'),
                                list('Q140_2', 'Q142_2', 'Q153_2', 'N masses'),
                                list('Q140_3', 'Q142_3', 'Q153_3', 'N bounces'),
                                list('Q141_1', 'Q157_1', 'Q154_1', 
                                     'Explanations'),
                                list('Q141_2', 'Q157_2', 'Q154_2', 'Analysis'),
                                list('Q141_3', 'Q157_3', 'Q154_3', 
                                     'Similar k values'),
                                list('Q141_4', 'Q157_4', 'Q154_4', 
                                     'Uncertainty in data'))

Likert.compare.summary <- function(df, Group1, Group2, Compare, Question, 
                                   summary = TRUE){
  df.temp <- df[, c(Group1, Group2, Compare)]
  colnames(df.temp) <- c('Group.1', 'Group.2', 'Comparison')
  df.temp$Group.1 <- as.numeric(df.temp$Group.1)
  df.temp$Group.2 <- as.numeric(df.temp$Group.2)

  if(summary){
    df.summary <- df.temp %>%
    filter(!is.na(Group.1) & !is.na(Group.2) & (Comparison != '')) %>%
    group_by(Group.1, Group.2, Comparison) %>%
    summarize(N = n())
  } else {
    df.summary <- df.temp
  }
  
  df.summary[, 'Aspect'] <- Question
  return(df.summary)
}

df.Likert.comparison <- df.students %>%
  filter(Condition %like% 'Likert')

df.Likert.comparison <- 
  rbind.fill(lapply(Likert.comparison.items,  
                    function(x) Likert.compare.summary(df = df.Likert.comparison,
                                                       Group1 = x[[1]], 
                                                       Group2 = x[[2]],
                                                       Compare = x[[3]], 
                                                       Question = x[[4]])))

df.Likert.comparison$Group.1 <- df.Likert.comparison$Group.1 - 
  0.1 * (df.Likert.comparison$Comparison %in% c('1', 'B')) + 
  0.1 * (df.Likert.comparison$Comparison %in% c('2', 'N'))
df.Likert.comparison$Group.2 <- df.Likert.comparison$Group.2 - 
  0.1 * (df.Likert.comparison$Comparison %in% c('B', 'N')) + 
  0.1 * (df.Likert.comparison$Comparison %in% c('1', '2'))

df.Likert.comparison <- df.Likert.comparison %>%
  mutate(Comparison = case_when(
    Comparison == '1' ~ 'Group 1',
    Comparison == '2' ~ 'Group 2',
    Comparison == 'B' ~ 'Both groups',
    Comparison == 'N' ~ 'Neither group'
  ))

df.Likert.comparison.total <- df.Likert.comparison %>%
  group_by(Group.1, Group.2, Comparison) %>%
  summarize(N = sum(N)) %>%
  mutate(Aspect = 'All')

fig <- plot_ly(df.Likert.comparison.total, type = 'scatter', x = ~Group.1, 
               y = ~Group.2, size = ~N, color = ~Comparison, 
               text = ~paste('# students:', N, sep = ' '), colors = palette.4_2, 
               hoverinfo = 'text', marker = list(sizeref = 5, 
                                                 sizemode = 'diameter'))

for(items in Likert.comparison.items){
  fig <- fig %>% 
    add_trace(data = df.Likert.comparison[df.Likert.comparison$Aspect == 
                                            items[[4]],], visible = FALSE, 
              marker = list(sizeref = 1.5, sizemode = 'diameter'))
}

Likert.comparison.items <- append(list(list('All', 'All', 'All', 'All')), 
                                  Likert.comparison.items)

fig <- fig %>%
  layout(xaxis = list(title = 'Group 1 Likert'),
         yaxis = list(title = 'Group 2 Likert'),
         legend = list(title = list(text = '<b> Which group did better? </b>'), 
                       orientation = 'h', x = 0.5, y = 1.1),
         updatemenus = list(
           list(
             x = 1.1,
             y = 1.2,
             buttons = lapply(Likert.comparison.items, function(set){
               list(method = 'restyle',
                    args = list('visible', 
                                c(unlist(Likert.comparison.items) %in% set)),
                    label = set[[4]])
             })
           )
         ))
fig
```
```{r}
Likert.comparison.items <- list(list('Q139_1', 'Q2d_1', 'Q152_1', 
                                     'Equipment used'),
                                list('Q139_2', 'Q2d_2', 'Q152_2', 
                                     'Variables measured'),
                                list('Q139_3', 'Q2d_3', 'Q152_3', 
                                     'Variables controlled'),
                                list('Q140_1', 'Q142_1', 'Q153_1', 'N trials'),
                                list('Q140_2', 'Q142_2', 'Q153_2', 'N masses'),
                                list('Q140_3', 'Q142_3', 'Q153_3', 'N bounces'),
                                list('Q141_1', 'Q157_1', 'Q154_1', 
                                     'Explanations'),
                                list('Q141_2', 'Q157_2', 'Q154_2', 'Analysis'),
                                list('Q141_3', 'Q157_3', 'Q154_3', 
                                     'Similar k values'),
                                list('Q141_4', 'Q157_4', 'Q154_4', 
                                     'Uncertainty in data'))

beachball.plot(df.students, Likert.comparison.items, Which = 'All')
beachball.plot(df.students, Likert.comparison.items, Which = 'All', scale = TRUE)
```

```{r, eval = FALSE}
df.Likert.comparison <- df.students %>%
  filter(Condition %like% 'Likert')

df.Likert.comparison.test <- 
  rbind.fill(lapply(Likert.comparison.items[2:length(Likert.comparison.items)],  
                    function(x) Likert.compare.summary(df = df.Likert.comparison,
                                                       Group1 = x[[1]], 
                                                       Group2 = x[[2]],
                                                       Compare = x[[3]], 
                                                       Question = x[[4]], 
                                                       summary = FALSE)))
df.Likert.comparison.test

df.Likert.comparison.test$Comparison <- 
  relevel(as.factor(df.Likert.comparison.test$Comparison), ref = 'B')
mod <- multinom(Comparison ~ Group.1 * Group.2 * Aspect, 
                df.Likert.comparison.test)
summary(mod)
p <- ggcoefstats(mod, output = 'tidy') %>%
  filter(term %like% ':Aspect') %>%
  ggcoefstats(.)
p
```


**Question 4 from email thread**

There's some mismatch between the Likert and comparison questions. I'm not sure if its **That** bad, but maybe we should think about ways to quantify this?

**Need quantitivative measure of overall disagreement.**

## Multiple response items
```{r, warning = FALSE, message = FALSE, echo = FALSE}
# pull only the 'what's next' questions (and condition variables)
Questions <- c('Q1b', 'Q1e', 'Q2b', 'Q2e', 'Q3b', 'Q3d', 'Q3e')
question_text <- data.frame(lapply(read.csv('PLIC_November2020.csv', nrows = 1),
                                   FUN = function(x) paste(gsub("\\? .*$", "", x), 
                                                           '?', sep = '')))
question_text <- data.frame(t(question_text)) %>%
  `colnames<-`('Text')
question_text$index <- row.names(question_text)
question_text <- question_text %>%
  mutate(index = gsub('134', '1e', index),
         index = gsub('145', '3b', index),
         index = gsub('147', '3e', index),
         index = gsub('_.*$', '', index),
         Text = gsub('Team Panda', 'Group 1', Text),
         Text = gsub('Team Ostrich', 'Group 2', Text),
         Text = paste(Text, ' (', index, ')', sep = '')) %>%
  filter(!duplicated(index) & index %in% Questions)

add.line.skip <- function(text){
  split.str <- strsplit(text, ' ')[[1]]
  middle.char <- round(length(split.str)/2, 0)
  split.str[middle.char] <- paste('\n', split.str[middle.char], sep = '')
  return(paste(split.str, collapse = ' '))
}
question_text$Text <- sapply(question_text$Text, add.line.skip)

df.multipleResponse <- 
  df.students[, grepl('(Q(1b|329|134|336|2b|341|2e|348|145|3d|147)_(\\d+)$|Condition|Likert|G2.First)',
                      names(df.students))] %>%
  mutate(id = row.names(.)) %>% # need an ID column to convert back to wide
  melt(., id.vars = c('id', 'Condition', 'Likert', 'G2.First'), 
       variable.name = 'Response_choice') %>%
  # combine 'next' questions from Likert and None conditions into single variable
  mutate(value = ifelse(is.na(value), 0, 1),
         value = ifelse(Likert == 1 & 
                          Response_choice %like% 'Q329|Q336|Q341|Q348', 
                        NA_real_, value),
         value = ifelse(Likert == 0 & Response_choice %like% 'Q1b|Q134|Q2b|Q2e', 
                        NA_real_, value),
         Response_choice = str_replace(Response_choice, '329', '1b'),
         Response_choice = str_replace(Response_choice, '336', '134'),
         Response_choice = str_replace(Response_choice, '341', '2b'),
         Response_choice = str_replace(Response_choice, '348', '2e'),
         Response_choice = gsub('134', '1e', Response_choice),
         Response_choice = gsub('145', '3b', Response_choice),
         Response_choice = gsub('147', '3e', Response_choice)) %>%
  na.omit() %>%
  rowwise() %>%
  mutate(Item = strsplit(as.character(Response_choice), '_')[[1]][1]) %>%
  data.table(.)

df.multipleResponse.wide <- df.multipleResponse

df.multipleResponse <- 
  df.multipleResponse[, Total := .N, by = c('Condition', 'Response_choice')] %>%
  data.frame(.) %>%
  group_by(Condition, Item, Response_choice, Total) %>%
  summarize(N = sum(value)) %>%
  mutate(Frac = N/Total) %>%
  select(Condition, Item, Response_choice, Frac) %>%
  mutate(Condition = str_replace(Condition, '-', '_')) %>% 
  rowwise() %>%
  mutate(RC_code = strsplit(as.character(Response_choice), '_')[[1]][2])

info.t <- data.frame(t(info)) %>%
  `colnames<-`('Text')
info.t$index <- row.names(info.t)
info.t <- info.t %>%
  mutate(index = gsub('134', '1e', index),
         index = gsub('145', '3b', index),
         index = gsub('147', '3e', index))

df.multipleResponse <- left_join(df.multipleResponse, info.t, 
                                 by = c('Response_choice' = 'index'))

df.multipleResponse <- dcast(df.multipleResponse, 
                             Item + Response_choice + RC_code + Text ~ Condition, 
                             value.var = 'Frac') %>%
  mutate(RC_code = as.numeric(RC_code)) %>%
  group_by(Item) %>%
  mutate(RC_code = rank(RC_code))

fig <- plot_ly(df.multipleResponse[df.multipleResponse$Item == Questions[1],], 
               type = 'bar', x = ~RC_code, y = ~Likert_1, text = ~Text, 
               name = 'Likert-1', color = I(palette.4[1])) %>% 
  add_trace(y = ~Likert_2, text = ~Text, name = 'Likert-2', 
            color = I(palette.4[2])) %>%
  add_trace(y = ~None_1, text = ~Text, name = 'None-1', 
            color = I(palette.4[3])) %>%
  add_trace(y = ~None_2, text = ~Text, name = 'None-2', 
            color = I(palette.4[4]))

for(Q in Questions[-1]){
  fig <- fig %>% 
    add_trace(data = df.multipleResponse[df.multipleResponse$Item == Q,], 
              y = ~Likert_1, text = ~Text, name = 'Likert-1', 
              color = I(palette.4[1]), visible = FALSE) %>% 
    add_trace(data = df.multipleResponse[df.multipleResponse$Item == Q,], 
              y = ~Likert_2, text = ~Text, name = 'Likert-2', 
              color = I(palette.4[2]), visible = FALSE) %>% 
    add_trace(data = df.multipleResponse[df.multipleResponse$Item == Q,], 
              y = ~None_1, text = ~Text, name = 'None-1', color = I(palette.4[3]), 
              visible = FALSE) %>% 
    add_trace(data = df.multipleResponse[df.multipleResponse$Item == Q,], 
              y = ~None_2, text = ~Text, name = 'None-2', color = I(palette.4[4]), 
              visible = FALSE)
}

fig <- fig %>%
  layout(barmode = 'group',
         xaxis = list(title = 'Selection'),
         yaxis = list(title = 'Fraction of respondents'),
         updatemenus = list(
           list(
             x = 0.75,
             y = 1.1,
             buttons = lapply(Questions, function(Q){
               list(method = 'restyle',
                    args = list('visible', c(rbind(Questions == Q, 
                                                   Questions == Q,
                                                   Questions == Q, 
                                                   Questions == Q))),
                    label = question_text[question_text$index == Q, 'Text'])
             })
           )
         ))

fig
```
*Questions 6 and 7 from email thread**

**Question 6**
Students typically suggest next steps (for both groups) along the lines of *reduce uncertainty, take more trials*, and for Group 1, students typically suggest testing more mases, while for Group 2, students typically suggest comparing the *k*-values to the expected value.

**Question 7** 
For Group 1, contrasting cases affects whether students suggest taking more trials (x = 2). Students are more likely to suggest Group 1 take more trials if they see Group 1 first.

For Group 2 (fixed intercept), contrasting cases affects whether students suggest testing other variables (x = 2; this might be a combination of scaffolding and contrasting cases), changing the analysis (x = 4), or testing other masses (x = 9).

After changing the intercept, only the next step to test other masses (x = 9) persists.

```{r}
df.multipleResponse <- 
  df.students[, grepl('(Q(1b|329|134|336|2b|341|2e|348|145|3d|147)_(\\d+)$|Condition|Likert|G2.First)',
                      names(df.students))] %>%
  mutate(id = row.names(.)) %>% # need an ID column to convert back to wide
  melt(., id.vars = c('id', 'Condition', 'Likert', 'G2.First'), 
       variable.name = 'Response_choice') %>%
  # combine 'next' questions from Likert and None conditions into single variable
  mutate(value = ifelse(is.na(value), 0, 1),
         value = ifelse(Likert == 1 & 
                          Response_choice %like% 'Q329|Q336|Q341|Q348', 
                        NA_real_, value),
         value = ifelse(Likert == 0 & Response_choice %like% 'Q1b|Q134|Q2b|Q2e', 
                        NA_real_, value),
         Response_choice = str_replace(Response_choice, '329', '1b'),
         Response_choice = str_replace(Response_choice, '336', '134'),
         Response_choice = str_replace(Response_choice, '341', '2b'),
         Response_choice = str_replace(Response_choice, '348', '2e'),
         Response_choice = gsub('134', '1e', Response_choice),
         Response_choice = gsub('145', '3b', Response_choice),
         Response_choice = gsub('147', '3e', Response_choice)) %>%
  na.omit() %>%
  rowwise() %>%
  mutate(Item = strsplit(as.character(Response_choice), '_')[[1]][1]) %>%
  data.table(.)

df.multipleResponse.wide <- df.multipleResponse

df.multipleResponse <- 
  df.multipleResponse[, Total := .N, by = c('G2.First', 'Response_choice')] %>%
  data.frame(.) %>%
  group_by(G2.First, Item, Response_choice, Total) %>%
  summarize(N = sum(value)) %>%
  mutate(Frac = N/Total) %>%
  select(G2.First, Item, Response_choice, Frac) %>%
  mutate(G2.First = str_replace(G2.First, '-', '_')) %>% 
  rowwise() %>%
  mutate(RC_code = strsplit(as.character(Response_choice), '_')[[1]][2])

info.t <- data.frame(t(info)) %>%
  `colnames<-`('Text')
info.t$index <- row.names(info.t)
info.t <- info.t %>%
  mutate(index = gsub('134', '1e', index),
         index = gsub('145', '3b', index),
         index = gsub('147', '3e', index))

df.multipleResponse <- left_join(df.multipleResponse, info.t, 
                                 by = c('Response_choice' = 'index'))

df.multipleResponse <- dcast(df.multipleResponse, 
                             Item + Response_choice + RC_code + Text ~ G2.First, 
                             value.var = 'Frac') %>%
  mutate(RC_code = as.numeric(RC_code)) %>%
  group_by(Item) %>%
  mutate(RC_code = rank(RC_code),
         diff = ifelse(Item %like% '1', `0` - `1`, `1` - `0`))

df.temp <- df.multipleResponse %>%
  filter((Item %like% 'e') & !(Text %like% 'Other')) %>%
  mutate(Text = case_when(
    (Text == 'Use a different analysis (e.g., graph the results, incorporate systematic effects)') | 
      (Text == 'Change the analysis (e.g., use a different fit line, incorporate systematic effects)') ~ 'Change the analysis',
    Text == 'Reduce uncertainty (e.g., more trials for the same masses, more bounces per trial, etc.)' ~ 'Take more trials/bounces',
    Text == 'Compare their k-values to the expected value' ~ 'Compare their k-value to the expected value',
    TRUE ~ Text
  ))

df.temp$Text <- sapply(df.temp$Text, add.line.skip)
df.levels <- df.temp %>%
  group_by(Text) %>%
  summarize(avg.diff = mean(diff)) %>%
  arrange(avg.diff)
  
df.levels

ggplot(df.temp, aes(x = factor(Text, levels = df.levels$Text), y = diff, 
                    group = Item, fill = Item)) +
  geom_bar(stat = 'identity', position = 'dodge') +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_text(angle = 60, hjust = 1),
        axis.ticks.x = element_blank()) +
  scale_fill_manual(values = palette.4, labels = c('Group 1', 'Group 2', 
'Group 2 (cont.)')) +
  labs(title = 'Difference in fraction of students\nselecting next steps (no CC - CC)',
       y = 'Difference', 
       fill ='Question Set')
```


```{r, warning = FALSE, message = FALSE, include = FALSE}
df.multipleResponse.wide <- df.multipleResponse.wide %>%
  rowwise() %>%
  mutate(RC_code = as.numeric(strsplit(as.character(Response_choice), 
                                       '_')[[1]][2])) %>%
  group_by(Item) %>%
  mutate(RC_code = paste('R', dense_rank(RC_code), sep = ''))

examine.item <- function(df, Q, type = 'N', p.value = FALSE, wide.data = FALSE){
  df <- dcast(df %>%
                filter(Item == Q), formula = id + Condition ~ RC_code,
              fun.aggregate = sum, value.var = "value") %>%
    data.frame(.) %>%
    select(-id)
  if(type == 'N'){
    df <- df %>%
      mutate(N.selections = rowSums(.[, -1]),
             Item = Q)
    if(p.value){
      print(Q)
      print(kruskal.test(N.selections ~ Condition, df)$p.value)
    }
    if(wide.data){
      return(df)
    }
    
    df <- df %>%
      count(Item, Condition, N.selections) %>%
      data.table(.)
    df <- df[, Total := sum(n), by = 'Condition'][, Frac := n/Total] %>%
      data.frame(.)
    return(df)
  } else {
      x <- MI.test(df, I = 1, J = (length(colnames(df)) - 1), type = 'all', 
                   B = 100, print.status = FALSE)
      print(c('boot' = x$boot$p.value.boot, 'rs2' = x$rs2$p.value.rs2, 
              'bon' = x$bon$p.value.bon))
      print(x$bon$X.sq.S.ij.p.bon)
  }
}

examine.item(df.multipleResponse.wide, 'Q1e', 'test')
```

### Likert vs. *What to do next*
```{r}
Likert.next.items <- list(list('Q139_1', 'Q134_9', 
                                     'Equipment used (Group 1)'),
                                list('Q139_2', 'Q134_1', 
                                     'Variables measured (Group 1)'), 
                                list('Q139_3', 'Q134_1', 
                                     'Variables controlled (Group 1)'),
                                list('Q140_1', 'Q134_2', 'N trials (Group 1)'), 
                                list('Q140_2', 'Q134_3', 'N masses (Group 1)'),
                                list('Q140_3', 'Q134_2', 'N bounces (Group 1)'),
                                list('Q141_2', 'Q134_4', 'Analysis (Group 1)'),
                                list('Q141_4', 'Q134_2', 
                                     'Uncertainty in data (Group 1)'),
                                list('Q2d_1', 'Q2e_4', 'Equipment used (Group 2)'),
                                list('Q2d_2', 'Q2e_6', 
                                     'Variables measured (Group 2)'),
                                list('Q2d_3', 'Q2e_6', 
                                     'Variables controlled (Group 2)'),
                                list('Q142_1', 'Q2e_16', 'N trials (Group 2)'),
                                list('Q142_2', 'Q2e_34', 'N masses (Group 2)'),
                                list('Q142_3', 'Q2e_16', 'N bounces (Group 2)'),
                                list('Q157_2', 'Q2e_12', 'Analysis (Group 2)'),
                                list('Q157_4', 'Q2e_16', 
                                     'Uncertainty in data (Group 2)'))

Likert.next.summary <- function(df, Likert, Next, Item){
  df.summary <- df %>%
    group_by_(Likert, Next) %>%
    summarize(N = n()) %>%
    filter(!is.na(!!as.symbol(Likert)))

  df.summary <- data.table(df.summary)[, Frac := N/sum(N), by = Likert] %>%
    data.frame(.) %>%
    mutate('Likert' = !!as.symbol(Likert),
           'Next' = ifelse(is.na(!!as.symbol(Next)), 0, 1),
           'Item' = Item) %>%
    select(Likert, Next, Item, N, Frac)
  
    return(df.summary)
}

df.Likert.next <- df.students[df.students$Condition %like% 'Likert',
                              names(df.students)[names(df.students) %in% 
                                                   unlist(Likert.next.items)]]

df.Likert.next <- 
  rbind.fill(lapply(Likert.next.items,  
                    function(x) Likert.next.summary(df = df.Likert.next,
                                                    Likert = x[[1]], 
                                                    Next = x[[2]],
                                                    Item = x[[3]])))

fig <- plot_ly(df.Likert.next[(df.Likert.next$Item == 
                                Likert.next.items[[1]][[3]]) & 
                                (df.Likert.next$Next == 0),], type = 'bar', 
               x = ~Likert, y = ~Frac, text = ~paste('# students:', N, sep = ' '), 
               color = I(palette.2_3[1]), hoverinfo = 'text', name = 'No') %>%
  add_trace(data = df.Likert.next[(df.Likert.next$Item == 
                                Likert.next.items[[1]][[3]]) & 
                                (df.Likert.next$Next == 1),], type = 'bar', 
            x = ~Likert, y = ~Frac, text = ~paste('# students:', N, sep = ' '), 
            color = I(palette.2_3[2]), hoverinfo = 'text', name = 'Yes')

for(items in Likert.next.items[-1]){
  fig <- fig %>% 
    add_trace(data = df.Likert.next[(df.Likert.next$Item == 
                                items[[3]]) & (df.Likert.next$Next == 0),], 
              type = 'bar', x = ~Likert, y = ~Frac, 
              text = ~paste('# students:', N, sep = ' '), 
              color = I(palette.2_3[1]), hoverinfo = 'text', name = 'No', 
              visible = FALSE) %>%
    add_trace(data = df.Likert.next[(df.Likert.next$Item == 
                                items[[3]]) & (df.Likert.next$Next == 1),], 
              type = 'bar', x = ~Likert, y = ~Frac, 
              text = ~paste('# students:', N, sep = ' '), 
              color = I(palette.2_3[2]), hoverinfo = 'text', name = 'Yes', 
              visible = FALSE)
}

Likert.next.items.first <- lapply(Likert.next.items, `[[`, 1)

fig <- fig %>%
  layout(barmode = 'group',
         xaxis = list(title = 'Likert'),
         yaxis = list(title = 'Fraction of respondents'),
         legend = list(title = list(text = '<b> Next step selected? </b>'),
                       orientation = 'h', x = 0.5, y = 1.1),
         updatemenus = list(
           list(
             x = 1.1,
             y = 1.2,
             buttons = lapply(Likert.next.items, function(set){
               list(method = 'restyle',
                    args = list('visible', 
                                c(rbind(Likert.next.items.first %in% set[[1]],
                                        Likert.next.items.first %in% set[[1]]))),
                    label = set[[3]])
             })
           )
         ))
fig
```
Have to dig into this a little more, but, in some cases, students' responses to the Likert items align with their responses to the *next steps* items and in some cases (particularly the number of masses used by Group 2) they do not.

### Number of selections
```{r}
df.selections <- bind_rows(lapply(Questions, examine.item, 
                                  df = df.multipleResponse.wide)) %>%
  mutate(Condition = str_replace(Condition, '-', '_')) %>%
  dcast(., formula = Item + N.selections ~ Condition,
              fun.aggregate = sum, value.var = "Frac")

fig <- plot_ly(df.selections[df.selections$Item == Questions[1],], 
               type = 'bar', x = ~N.selections, y = ~Likert_1, name = 'Likert-1', 
               color = I(palette.4[1])) %>% 
  add_trace(y = ~Likert_2, name = 'Likert-2', color = I(palette.4[2])) %>%
  add_trace(y = ~None_1, name = 'None-1', color = I(palette.4[3])) %>%
  add_trace(y = ~None_2, name = 'None-2', color = I(palette.4[4]))

for(Q in Questions[-1]){
  fig <- fig %>% 
    add_trace(data = df.selections[df.selections$Item == Q,], 
              y = ~Likert_1, name = 'Likert-1', color = I(palette.4[1]), 
              visible = FALSE) %>% 
    add_trace(data = df.selections[df.selections$Item == Q,], 
              y = ~Likert_2, name = 'Likert-2', color = I(palette.4[2]), 
              visible = FALSE) %>% 
    add_trace(data = df.selections[df.selections$Item == Q,], 
              y = ~None_1, name = 'None-1', color = I(palette.4[3]), 
              visible = FALSE) %>% 
    add_trace(data = df.selections[df.selections$Item == Q,], 
              y = ~None_2, name = 'None-2', color = I(palette.4[4]), 
              visible = FALSE)
}

fig <- fig %>%
  layout(barmode = 'group',
         xaxis = list(title = 'Number of selections'),
         yaxis = list(title = 'Fraction of respondents'),
         updatemenus = list(
           list(
             x = 0.75,
             y = 1.1,
             buttons = lapply(Questions, function(Q){
               list(method = 'restyle',
                    args = list('visible', c(rbind(Questions == Q, 
                                                   Questions == Q,
                                                   Questions == Q, 
                                                   Questions == Q))),
                    label = question_text[question_text$index == Q, 'Text'])
             })
           )
         ))

fig
```
I thought that one possible explanation for the differences in selection patterns when contrasting cases are present could be that respondents aren't selecting as many things after seeing a contrasting case and are more focused in the things they select.

I might be right on this for **Group 1** (Q1e); there's about a 7-10 percentage point drop in the number of students selecting two responses after seeing the contrasting case, but this pattern doesn't hold for Group 2.

#### Students that only select one response
```{r}
df.selections.oneSelection <- bind_rows(lapply(Questions, examine.item, 
                                  df = df.multipleResponse.wide, 
                                  wide.data = TRUE)) %>%
  mutate(Condition = str_replace(Condition, '-', '_')) %>%
  filter(N.selections == 1) %>%
  select(-N.selections) %>%
  group_by(Item, Condition) %>%
  summarize_all(mean) %>%
  melt(., id.vars = c('Item', 'Condition')) %>%
  dcast(., Item + variable ~ Condition, value.var = 'value') %>%
  na.omit() %>%
  left_join(., df.multipleResponse %>%
              mutate(RC_code = paste('R', RC_code, sep = '')) %>%
              select(Item, RC_code, Text), by = c('Item' = 'Item', 
                                                  'variable' = 'RC_code'))%>%
  rowwise() %>%
  mutate(variable = as.numeric(strsplit(as.character(variable), 'R')[[1]][2]))

fig <- 
  plot_ly(df.selections.oneSelection[df.selections.oneSelection$Item == Questions[1],], 
          type = 'bar', x = ~variable, y = ~Likert_1, text = ~Text, 
          name = 'Likert-1', color = I(palette.4[1])) %>% 
  add_trace(y = ~Likert_2, name = 'Likert-2', text = ~Text, 
            color = I(palette.4[2])) %>%
  add_trace(y = ~None_1, name = 'None-1', text = ~Text, 
            color = I(palette.4[3])) %>%
  add_trace(y = ~None_2, name = 'None-2', text = ~Text, color = I(palette.4[4]))

for(Q in Questions[-1]){
  fig <- fig %>% 
    add_trace(data = df.selections.oneSelection[df.selections.oneSelection$Item == Q,], 
              y = ~Likert_1, text = ~Text, name = 'Likert-1', 
              color = I(palette.4[1]), visible = FALSE) %>% 
    add_trace(data = df.selections.oneSelection[df.selections.oneSelection$Item == Q,], 
              y = ~Likert_2, text = ~Text, name = 'Likert-2', 
              color = I(palette.4[2]), visible = FALSE) %>% 
    add_trace(data = df.selections.oneSelection[df.selections.oneSelection$Item == Q,], 
              y = ~None_1, text = ~Text, name = 'None-1', color = I(palette.4[3]), 
              visible = FALSE) %>% 
    add_trace(data = df.selections.oneSelection[df.selections.oneSelection$Item == Q,], 
              y = ~None_2, text = ~Text, name = 'None-2', color = I(palette.4[4]), 
              visible = FALSE)
}

fig <- fig %>%
  layout(barmode = 'group',
         xaxis = list(title = ''),
         yaxis = list(title = 'Fraction of respondents'),
         updatemenus = list(
           list(
             x = 0.75,
             y = 1.1,
             buttons = lapply(Questions, function(Q){
               list(method = 'restyle',
                    args = list('visible', c(rbind(Questions == Q, 
                                                   Questions == Q,
                                                   Questions == Q, 
                                                   Questions == Q))),
                    label = question_text[question_text$index == Q, 'Text'])
             })
           )
         ))

fig
```
Thought looking at students who only selected one response might give us an idea of what students find most salient. Haven't looked into this yet.

```{r}
df.students %>%
  group_by(Likert) %>%
  summarize(median(Duration..in.seconds.))

(1037.5 - 906)/1037.5
```


## Time spent on page
```{r, eval = FALSE}
df.time <- 
  df.students[, c(names(df.students)[names(df.students) %like% 'Submit|Qt\\d_3'],
                  'Condition')] %>%
  mutate(Group1.t = ifelse(!is.na(Qt1_3), Qt1_3, Q338_Page.Submit),
         Group2.t = ifelse(!is.na(Qt2_3), Qt2_3, Q351_Page.Submit),
         Group2.cont.t = Qt3_3,
         Compare.t = Qt4_3,
         id = row.names(.)) %>%
  select(Condition, Group1.t, Group2.t, Group2.cont.t, Compare.t, id) %>%
  melt(., id.vars = c('id', 'Condition'), variable.name = 'Page', 
       value.name = 'Time') %>%
  mutate(Page = case_when(
    Page == 'Group1.t' ~ 'Group 1',
    Page == 'Group2.t' ~ 'Group 2',
    Page == 'Group2.cont.t' ~ 'Group 2 (cont.)',
    Page == 'Compare.t' ~ 'Comparison'
  ),
  Page = factor(Page, levels = c('Group 1', 'Group 2', 'Group 2 (cont.)', 
                                 'Comparison')))

p <- ggplot(df.time, aes(x = Page, y = Time, color = Condition)) +
  geom_boxplot() +
  scale_color_manual(values = palette.4) +
  ylim(0, 600)

ggplotly(p) %>%
  layout(boxmode = "group")
```
A few things:

1. Students that take a Likert version, take longer (no surprise).

2. Students spend more time on a page if its the first page they see. Students in the Likert-1 and None-1 conditions spend longer on Group 1's page than the conditions that saw Group 2 first. The same pattern holds for Group 2's page. This could suggest that when a contrasting case is available, students are able to progess quicker. Or it could just be that students are gaining familiarity with the assessment and moving faster. Although some students see Group 2 (cont.) second and some see it third and there seems to be no difference in the time it takes students to complete this item regardless lending support to the first hypothesis.

3. Students that don't see Likert items throughout take a little longer to complete the comparison questions, probably because this is the first time they are explicitly evaluating specific details of the experiments.

```{r, eval = FALSE}
df.time <- df.time %>% 
  mutate(Likert = 1 * grepl('Likert', df.time$Condition),
         G2.First = 1 * grepl('2', df.time$Condition))
mod <- lmer(Time ~ (Likert + G2.First) * Page + (1 | id), df.time)
summary(mod)
plot(mod)
```

```{r, eval = FALSE}
df.time <- df.time %>%
  mutate(Submit = 1)

mod <- coxph(Surv(Time, Submit) ~ (Likert + G2.First) * Page, df.time)
summary(mod)

ggsurvplot(survfit(mod, data = df.time))

unique(df.time[, c('Likert', 'G2.First', 'Page')]) 
      
survfit(mod, newdata = unique(df.time[, c('Likert', 'G2.First', 'Page')]))

plot(survfit(mod, newdata = unique(df.time[, c('Likert', 'G2.First', 'Page')])), xlim = c(0, 600), conf.int = FALSE)
p$data.survplot
```



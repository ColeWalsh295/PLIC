```{r}
library(xlsx)
library(MASS)
library(Rcpp)
library(reshape2)
library(broom)
library(plyr)
library(infer)
library(boot)
library(effsize)
library(psych)
library(tidyverse)
library(lsr)
```

```{r include=FALSE}
#df <- read.csv('C:/Users/Cole/Documents/GRA_Summer2018/Surveys/Collective_Surveys/Completely_Merged_Dataset10292018.csv')

df <- read.csv('C:/Users/Cole/Documents/GRA_Summer2018/Surveys/Collective_Surveys/Completely_Merged_Dataset12022018.csv')

df_CIS <- read.csv('C:/Users/Cole/Documents/GRA_Summer2018/Surveys/Collective_Surveys/Course_Information_Survey.csv')[-1,]

nrow(df)
str(df)
```

# CIS cleaning
```{r}
df_CIS_cleaned <- df_CIS %>%
  mutate(Semester = case_when(
    Q9a == 1 ~ 'Fall',
    (Q9 == 1 & Q9a == 2) | (Q9 == 2 & Q9b == 3) ~ 'Spring',
    (Q9 == 1 & Q9a == 3) | (Q9 == 2 & Q9b == 4) ~ 'Summer',
    (Q9 == 1 & Q9a == 4) | (Q9 == 2 & Q9b == 5) ~ 'Year',
    Q9 == 2 & Q9b == 2 ~ 'Winter',
    TRUE ~ NA_character_
  ),
  Lab_Level = case_when(
    Q7 == 1 ~ 'Intro-Algebra',
    Q7 == 2 ~ 'Intro-Calculus',
    Q7 == 3 ~ 'Sophomore',
    Q7 == 4 ~ 'Junior',
    Q7 == 5 ~ 'Senior',
    TRUE ~ NA_character_
  ),
  Where_Completed = case_when(
    Q44 == 1 ~ 'In Class/Lab',
    Q44 == 2 ~ 'At Home',
    TRUE ~ NA_character_
  ),
  N_Students = Q8,
  School = case_when(
    Q4 == 'UBC' ~ 'University of British Columbia',
    Q4 == 'University of Maine Orono' ~ 'University of Maine',
    Q4 == 'University of Maine, Orono' ~ 'University of Maine',
    Q4 == '1971' ~ 'CSU Chico',
    Q4 == 'Cornell University ' ~ 'Cornell University',
    TRUE ~ as.character(Q4)),
  Institution_Type = case_when(
    Q19 == 1 ~ '2 year college',
    Q19 == 2 ~ '4 year college',
    Q19 == 3 ~ "Master's granting institution",
    Q19 == 4 ~ 'PhD granting institution',
    Q17 == 1 ~ 'Cole needs to input this info manually',
    TRUE ~ NA_character_
  ),
  Lab_Purpose = case_when(
    Q27 == 1 ~ 'Reinforce physics concepts',
    Q27 == 2 ~ 'Develop lab skills',
    Q27 == 3 ~ 'Both about equally',
    Q17 == 1 ~ 'Cole needs to input this info manually',
    TRUE ~ NA_character_
  )) %>%
  select(V1, Semester, Lab_Level, Where_Completed, N_Students, School, Institution_Type, Lab_Purpose)

df2 <- merge(df, df_CIS_cleaned, by.x = 'Class_ID', by.y = 'V1') %>%
  distinct(V1_x, V1_y, .keep_all = TRUE)

#print(df[(!(df$V1_y %in% df2$V1_y) | !(df$V1_y %in% df2$V1_y)), c('V1_x', 'V1_y')])

nrow(df2)
```

# CIS mutating and merging with main data and school and course information
```{r}
CTLabs <- c('R_6rq9bCkfvLDJEdz', 'R_3fNprNmbwV9C4X0', 'R_2R8MnTyv2jFgPzA', 'R_1IB300CxBKh0Tw7', 'R_1n7wUeClpEuZOkp')

# Check 1116 from Fall 2017 where half of the class fell into each lab

Pre1116_Intervention_IDS <-read.xlsx('C:/Users/Cole/Documents/GRA_Summer2018/Surveys/Fall2017/PRE/Fall2017_Cornell_University_1116_Smith_PRE_R_1Oko8BpPfb9rt0G_180202_I.xlsx', sheetIndex = 1) %>%
  filter(Intervention == 1) %>%
  select(V1)

Post1116_Intervention_IDS <-read.xlsx('C:/Users/Cole/Documents/GRA_Summer2018/Surveys/Fall2017/POST/Fall2017_Cornell_University_1116_Smith_POST_R_1Oko8BpPfb9rt0G_180202_I.xlsx', sheetIndex = 1) %>%
  filter(Intervention == 1) %>%
  select(V1)

df_cleaned <- df2 %>%
  mutate(Lab_Type = ifelse(Class_ID %in% CTLabs, 'Critical Thinking', 'Other'),
         Gender = case_when(
           Q6e_1_y == 1 ~ 'M',
           Q6e_2_y == 1 ~ 'F',
           Q6e_3_y == 1 ~ 'Other',
           Q6e_1_x == 1 ~ 'M',
           Q6e_2_x == 1 ~ 'F',
           Q6e_3_x == 1 ~ 'Other'
           ),
         Major = case_when(
           Q6b_y < 4 ~ 'Physics',
           Q6b.i_y == 1 ~ 'Engineering',
           Q6b.i_y == 2 | Q6b.i_y == 3 ~ 'Other Science',
           Q6b.i_y == 4 ~ 'Other',
           Q6b_x < 4 ~ 'Physics',
           Q6b.i_x == 1 ~ 'Engineering',
           Q6b.i_x == 2 | Q6b.i_x == 3 ~ 'Other Science',
           Q6b.i_x == 4 ~ 'Other'
           ),
         Ethnicity = case_when(
           Q6f_2_y == 1 ~ 'Asian/Asian American',
           Q6f_6_y == 1 ~ 'White/Caucasian',
           Q6f_1_y == 1 ~ 'American Indian/Alaska Native',
           Q6f_3_y == 1 ~ 'African American',
           Q6f_4_y == 1 ~ 'Hispanic/Latino',
           Q6f_5_y == 1 ~ 'Native Hawaiian/Pacific Islander',
           Q6f_7_y == 1 ~ 'Other',
           Q6f_2_x == 1 ~ 'Asian/Asian American',
           Q6f_6_x == 1 ~ 'White/Caucasian',
           Q6f_1_x == 1 ~ 'American Indian/Alaska Native',
           Q6f_3_x == 1 ~ 'African American',
           Q6f_4_x == 1 ~ 'Hispanic/Latino',
           Q6f_5_x == 1 ~ 'Native Hawaiian/Pacific Islander',
           Q6f_7_x == 1 ~ 'Other'
           ))

df_cleaned$Lab_Type[df2$V1_x %in% Pre1116_Intervention_IDS$V1] <- 'Critical Thinking'
df_cleaned$Lab_Type[df2$V1_y %in% Post1116_Intervention_IDS$V1] <- 'Critical Thinking'

print('Number of distinct classes...')
length(unique(df_cleaned$Class_ID))
print('Number of unique schools...')
length(unique(df_cleaned$School))
print(unique(df_cleaned$School))

df_cleaned %>%
  distinct(Class_ID, .keep_all = TRUE) %>%
  count(Institution_Type, Lab_Level)

df_cleaned$Survey_x[is.na(df_cleaned$Survey_x)] = 'F'
df_cleaned$Survey_y[is.na(df_cleaned$Survey_y)] = 'F'

df_cleaned$N_Students <- droplevels(df_cleaned$N_Students)
df_cleaned$N_Students <- as.numeric(levels(df_cleaned$N_Students))[df_cleaned$N_Students]

df_cleaned[(df_cleaned$Qt1_3_x < 30) & (df_cleaned$Qt2_3_x < 30) & (df_cleaned$Qt3_3_x < 30) & (df_cleaned$Qt4_3_x < 30) & (!is.na(df_cleaned$PreScores)) , 'PreScores'] <- NA
df_cleaned[(df_cleaned$Qt1_3_y < 30) & (df_cleaned$Qt2_3_y < 30) & (df_cleaned$Qt3_3_y < 30) & (df_cleaned$Qt4_3_y < 30) & (!is.na(df_cleaned$PostScores)), 'PostScores'] <- NA

df_cleaned <- df_cleaned %>%
  filter((!is.na(PreScores)) | (!is.na(PostScores)))

nrow(df_cleaned)
```

# Second data cleaning
```{r}
df_cleaned <- df_cleaned %>%
  mutate(Lab_Level = case_when(
    Lab_Level == 'Intro-Algebra' ~ 'FY',
    Lab_Level == 'Intro-Calculus' ~ 'FY',
    Lab_Level == 'Junior' ~ 'Advanced',
    Lab_Level == 'Senior' ~ 'Advanced',
    TRUE ~ 'Sophomore'
  ))

table(df_cleaned$Lab_Level)
table(df_cleaned$Lab_Type)
```

# Create matched dataset and pre- and post breakdown...and all datasets for later use
```{r}
df_pre <- df_cleaned %>%
  filter(!is.na(PreScores))

print('Number of pre surveys...')
nrow(df_pre)

df_pre_CR <- df_pre[df_pre$Survey_x == 'C',]

print('Number of CR pre survey...')
nrow(df_pre_CR)

df_post <- df_cleaned %>%
  filter(!is.na(PostScores))

print('Number of post surveys...')
nrow(df_post)

df_post_CR <- df_post[df_post$Survey_y == 'C',]

print('Number of CR post survey...')
nrow(df_post_CR)

df_matched <- df_cleaned %>%
  filter(!is.na(PreScores) & !is.na(PostScores))

print('All pre-surveys demographics...')
table(df_pre$Gender, useNA = "ifany")/nrow(df_pre) * 100
table(df_pre$Major, useNA = "ifany")/nrow(df_pre) * 100
table(df_pre$Ethnicity, useNA = "ifany")/nrow(df_pre) * 100

nrow(df_pre)
print('Estimated response rate...')
inv_frac <- df_pre %>%
  distinct(Class_ID, .keep_all = TRUE) %>%
  select(N_Students) %>%
  sum(.)/nrow(df_pre)
1/inv_frac

Pre_Frac <- df_pre %>%
  group_by(Class_ID) %>%
  mutate(N_complete = n()) %>%
  distinct(Class_ID, .keep_all = TRUE) %>%
  summarize(frac = N_complete/N_Students, N_Students) %>%
  arrange(frac)

Pre_Frac
print('Mean pre response rate...')
mean(Pre_Frac$frac)
sd(Pre_Frac$frac)/sqrt(nrow(Pre_Frac))

print('All post-surveys demographics...')
table(df_post$Gender, useNA = "ifany")/nrow(df_post) * 100
table(df_post$Major, useNA = "ifany")/nrow(df_post) * 100
table(df_post$Ethnicity, useNA = "ifany")/nrow(df_post) * 100

nrow(df_post)
print('Estimated response rate...')
inv_frac <- df_post %>%
  distinct(Class_ID, .keep_all = TRUE) %>%
  select(N_Students) %>%
  sum(.)/nrow(df_post)
1/inv_frac

Post_Frac <- df_post %>%
  group_by(Class_ID) %>%
  mutate(N_complete = n()) %>%
  distinct(Class_ID, .keep_all = TRUE) %>%
  summarize(frac = N_complete/N_Students, N_Students) %>%
  arrange(frac)

Post_Frac
print('Mean post response rate...')
mean(Post_Frac$frac)
sd(Post_Frac$frac)/sqrt(nrow(Post_Frac))

print('Matched-surveys demographics...')
table(df_matched$Gender, useNA = "ifany")/nrow(df_matched) * 100
table(df_matched$Major, useNA = "ifany")/nrow(df_matched) * 100
table(df_matched$Ethnicity, useNA = "ifany")/nrow(df_matched) * 100

print('Number of matched surveys...')
nrow(df_matched)

df_matched_CR <- df_matched %>%
  filter((Survey_x == 'C') & (Survey_y == 'C'))

print('Number of CR matched surveys...')
nrow(df_matched_CR)

print('N of CR-OR...')
df_matched %>%
  filter((Survey_x == 'C') & (Survey_y == 'F')) %>%
  nrow(.)

print('N of OR-CR...')
df_matched %>%
  filter((Survey_x == 'F') & (Survey_y == 'C')) %>%
  nrow(.)

print('N of OR-OR...')
df_matched %>%
  filter((Survey_x == 'F') & (Survey_y == 'F')) %>%
  nrow(.)
```

# Scores Histogram and matched average scores, and wilcox paired test of matched scores
```{r}
df <- df_matched_CR %>%
  select(PreScores, PostScores)

colnames(df) <- c('Pre', 'Post')

ggplot(melt(df), aes(value, fill = variable)) +
  geom_histogram(bins = 10, position = "dodge") +
  labs(x = 'Score on PLIC (/10)', y = 'Number of Students') +
  theme_minimal() +
  xlim(0, 10) +
  theme(text = element_text(size = 20), legend.position = c(0.1, 0.9), legend.title = element_blank(), legend.background = element_blank()) +
  scale_fill_manual(values=c("#a6bddb", "#2b8cbe")) +
  geom_vline(xintercept = 7.6, size = 2)

df %>%
  summarize(Pre_Avg = mean(Pre), Post_Avg = mean(Post))

boot.mean<-function(x,i){boot.mean<-mean(x[i])}
Summary_df <- apply(df, 2, function(y){ 
   b<-boot(y, boot.mean, R=10000);
   SE <- c(sd(b$t))
   c(mean(b$t), 1.96 * SE, boot.ci(b,type="perc", conf=0.95)$percent[4:5])
})
rownames(Summary_df) <- c('Boot Mean', '95%', 'Low', 'High')
Summary_df


t.test(df$Pre, df$Post, paired = TRUE)
effsize::cohen.d(df$Pre, df$Post)
```

# Item Difficulty and paired wilcox tests for each question
```{r}
#Pre_cols <- c('Q1As_x', 'Q1Bs_x', 'Q1Cs_x', 'Q1Ds_x', 'Q1Es_x', 'Q2As_x', 'Q2Bs_x', 'Q2Cs_x', 'Q2Ds_x', 'Q2Es_x', 'Q3As_x', 'Q3Bs_x', 'Q3Cs_x', 'Q3Ds_x', 'Q3Es_x', 'Q4As_x', 'Q4Bs_x')

#Post_cols <- c('Q1As_y', 'Q1Bs_y', 'Q1Cs_y', 'Q1Ds_y', 'Q1Es_y', 'Q2As_y', 'Q2Bs_y', 'Q2Cs_y', 'Q2Ds_y', 'Q2Es_y', 'Q3As_y', 'Q3Bs_y', 'Q3Cs_y', 'Q3Ds_y', 'Q3Es_y', 'Q4As_y', 'Q4Bs_y')

#Cols <- c('Q1A', 'Q1B', 'Q1C', 'Q1D', 'Q1E', 'Q2A', 'Q2B', 'Q2C', 'Q2D', 'Q2E', 'Q3A', 'Q3B', 'Q3C', 'Q3D', 'Q3E', 'Q4A', 'Q4B')

#Pre_cols <- c('Q1Bs_x', 'Q1Ds_x', 'Q1Es_x', 'Q2Bs_x', 'Q2Ds_x', 'Q2Es_x', 'Q3Bs_x', 'Q3Cs_x', 'Q3Ds_x', 'Q3Es_x', 'Q4As_x', 'Q4Bs_x')

#Post_cols <- c('Q1Bs_y', 'Q1Ds_y', 'Q1Es_y', 'Q2Bs_y', 'Q2Ds_y', 'Q2Es_y', 'Q3Bs_y', 'Q3Cs_y', 'Q3Ds_y', 'Q3Es_y', 'Q4As_y', 'Q4Bs_y')

#Cols <- c('Q1B', 'Q1D', 'Q1E', 'Q2B', 'Q2D', 'Q2E', 'Q3B', 'Q3C', 'Q3D', 'Q3E', 'Q4A', 'Q4B')

Pre_cols <- c('Q1Bs_x', 'Q1Ds_x', 'Q1Es_x', 'Q2Bs_x', 'Q2Ds_x', 'Q2Es_x', 'Q3Bs_x', 'Q3Ds_x', 'Q3Es_x', 'Q4Bs_x')

Post_cols <- c('Q1Bs_y', 'Q1Ds_y', 'Q1Es_y', 'Q2Bs_y', 'Q2Ds_y', 'Q2Es_y', 'Q3Bs_y', 'Q3Ds_y', 'Q3Es_y', 'Q4Bs_y')

Cols <- c('Q1B', 'Q1D', 'Q1E', 'Q2B', 'Q2D', 'Q2E', 'Q3B', 'Q3D', 'Q3E', 'Q4B')

df1 <- df_matched_CR[, Pre_cols]

df2 <- df_matched_CR[, Post_cols]

colnames(df1) <- Cols
colnames(df2) <- Cols

Pre <- colMeans(df1)
Post <- colMeans(df2)

Summary_df1 <- apply(df1, 2, function(y){ 
   b<-boot(y, boot.mean, R=10000);
   SE <- c(sd(b$t))
   c(mean(b$t), 1.96 * SE, boot.ci(b,type="perc", conf=0.95)$percent[4:5])
})
rownames(Summary_df1) <- c('Boot Mean', '95%', 'Low', 'High')
Summary_df1

Summary_df2 <- apply(df2, 2, function(y){ 
   b<-boot(y, boot.mean, R=10000);
   SE <- c(sd(b$t))
   c(mean(b$t), 1.96 * SE, boot.ci(b,type="perc", conf=0.95)$percent[4:5])
})
rownames(Summary_df2) <- c('Boot Mean', '95%', 'Low', 'High')
Summary_df2

df3 <- data.frame(cbind(Survey = 'Pre', Question = Cols, Mean = Pre, Low = Summary_df1['Low', ], High = Summary_df1['High', ]))
df4 <- data.frame(cbind(Survey = 'Post', Question = Cols, Mean = Post, Low = Summary_df2['Low', ], High = Summary_df2['High', ]))
df <- rbind(df3, df4)
rownames(df) <- NULL
df <- transform(df, Mean = as.numeric(levels(Mean))[Mean], Low = as.numeric(levels(Low))[Low], High = as.numeric(levels(High))[High])

df_rand <- read.csv('C:/Users/Cole/Documents/GRA_Summer2018/Surveys/Rand_Select3_S_new.csv') %>%
  select(Q1Bs, Q1Ds, Q1Es, Q2Bs, Q2Ds, Q2Es, Q3Bs, Q3Ds, Q3Es, Q4Bs) %>%
  `colnames<-`(c('Q1B', 'Q1D', 'Q1E', 'Q2B', 'Q2D', 'Q2E', 'Q3B', 'Q3D', 'Q3E', 'Q4B')) %>%
  colMeans() %>%
  as.data.frame.list() %>%
  melt() %>%
  `colnames<-` (c('Question', 'Mean')) %>%
  mutate(Survey = 'Pre')

Markers = df %>%
  filter((Question %in% c('Q1B', 'Q1D', 'Q1E', 'Q2B', 'Q2D', 'Q2E', 'Q3B')) & (Survey == 'Post')) %>%
  select(Survey, Question, High) %>%
  mutate(High = High + 0.05)
  
ggplot(df, aes(x = Question, y = Mean, group = Survey, colour = Survey)) +
  geom_point(size = 3, position = position_dodge(0.3)) +
  theme_minimal() +
  ylim(0.3, 0.8) +
  geom_errorbar(aes(ymin = Low, ymax = High), width = 0.6, size = 1.2, position = position_dodge(0.3)) +
  theme(text = element_text(size = 20), legend.position = c(0.1, 0.1), legend.title = element_blank(), legend.background = element_blank()) +
  labs(x = 'Question', y = 'Average Score') +
  scale_color_manual(values=c("#a6bddb", "#2b8cbe")) +
  #geom_point(data = Markers, aes(x = Question, y = High), color = "#045a8d", shape = 25, fill = "#045a8d", size = 4) +
  geom_point(data = df_rand, aes(x = Question, y = Mean), color = 'black', shape = 15, fill = 'black', size = 4)
  

melted_df1 <- melt(df1)
melted_df2 <- melt(df2)
melted_df <- cbind(melted_df1, melted_df2$value)
colnames(melted_df) <- c('Question', 'Pre', 'Post')
by(melted_df, melted_df$Question, function(x) wilcox.test(x$Pre, x$Post, mu=0, paired = TRUE))
by(melted_df, melted_df$Question, function(x) effsize::cohen.d(x$Pre, x$Post, mu=0))
```

# Holm-Bonferroni correction on p-values
```{r}
# Enter p-values calculated above in order to re-adjust

p_vals <- c(2.811e-08, 2.245e-07, 0.007832, 2.305e-11, 0.0001615, 0.0006396, 7.099e-11, 0.3128, 0.1379, 0.6953)

p.adjust(p_vals, method = "holm")
```


# Median Time and correlation with score
```{r}
df_matched_CR %>%
  summarize(Pre_MedianTime = median(Q_TotalDuration_x, na.rm = TRUE),
            N_Pre = sum(!is.na(Q_TotalDuration_x)),
            sd = sd(Q_TotalDuration_x, na.rm = TRUE))

df_matched_CR %>%
  summarize(Post_MedianTime = median(Q_TotalDuration_y, na.rm = TRUE),
            N_Post = sum(!is.na(Q_TotalDuration_y)),
            sd = sd(Q_TotalDuration_y, na.rm = TRUE))

dat_pre = ggplot(df_matched_CR, aes(x = 1, y = Q_TotalDuration_x)) +
  geom_boxplot()

y_max_pre <- data.frame(ggplot_build(dat_pre)$data)$ymax

dat_post = ggplot(df_matched_CR, aes(x = 1, y = Q_TotalDuration_y)) +
  geom_boxplot()

y_max_post <- data.frame(ggplot_build(dat_post)$data)$ymax

q = 0.05

df1 <- df_matched_CR %>%
  summarize(Low = quantile(Q_TotalDuration_x, q), High = quantile(Q_TotalDuration_x, 1 - q))

df2 <- df_matched_CR %>%
  summarize(Low = quantile(Q_TotalDuration_y, q), High = quantile(Q_TotalDuration_y, 1 - q))

df3 <- df_matched_CR %>%
  #filter((Q_TotalDuration_x >= df1$Low) & (Q_TotalDuration_x <= df1$High))
  #filter(Q_TotalDuration_x <= df1$High)
  filter(Q_TotalDuration_x <= y_max_pre)

df3 %>%
  summarize(frac = nrow(.)/nrow(df_matched_CR), min = min(Q_TotalDuration_x), med = median(Q_TotalDuration_x), max = max(Q_TotalDuration_x))

df4 <- df_matched_CR %>%
  #filter((Q_TotalDuration_y >= df2$Low) & (Q_TotalDuration_y <= df2$High))
  #filter(Q_TotalDuration_y <= df2$High)
  filter(Q_TotalDuration_y <= y_max_post)

df4 %>%
  summarize(frac = nrow(.)/nrow(df_matched_CR), min = min(Q_TotalDuration_y), med = median(Q_TotalDuration_y), max = max(Q_TotalDuration_y))

Pre_times <- df_matched_CR %>%
  filter(!is.na('Q_TotalDuration_x')) %>%
  specify(response = 'Q_TotalDuration_x') %>%
  generate(reps = 10000, type = "bootstrap") %>%
  calculate(stat = "median") %>%
  summarize(Mean = mean(stat), SE2 = 1.96 * sd(stat), low = quantile(stat, 0.025), high = quantile(stat, 0.975))

Post_times <- df_matched_CR %>%
  filter(!is.na('Q_TotalDuration_y')) %>%
  specify(response = 'Q_TotalDuration_y') %>%
  generate(reps = 10000, type = "bootstrap") %>%
  calculate(stat = "median") %>%
  summarize(Mean = mean(stat), SE2 = 1.96 * sd(stat), low = quantile(stat, 0.025), high = quantile(stat, 0.975))

Pre_times
Post_times

df_matched_CR %>%
  select(Q_TotalDuration_x, PreScores) %>%
  cor(use = "pairwise.complete.obs")

df_matched_CR %>%
  select(Q_TotalDuration_y, PostScores) %>%
  cor(use = "pairwise.complete.obs")

df3 %>%
  select(Q_TotalDuration_x, PreScores) %>%
  cor(use = "pairwise.complete.obs")

df4 %>%
  select(Q_TotalDuration_y, PostScores) %>%
  cor(use = "pairwise.complete.obs")
```

# Function for difference in correlations significance
```{r}
cor.diff.test = function(x1, x2, y1, y2, method="pearson") {
  cor1 = cor.test(x1, x2, method=method)
  cor2 = cor.test(y1, y2, method=method)

  r1 = cor1$estimate
  r2 = cor2$estimate
  n1 = sum(complete.cases(x1, x2))
  n2 = sum(complete.cases(y1, y2))
  fisher = ((0.5*log((1+r1)/(1-r1)))-(0.5*log((1+r2)/(1-r2))))/((1/(n1-3))+(1/(n2-3)))^0.5

  p.value = (2*(1-pnorm(abs(fisher))))

  result= list(
    "cor1" = list(
      "estimate" = as.numeric(cor1$estimate),
      "p.value" = cor1$p.value,
      "n" = n1
    ),
    "cor2" = list(
      "estimate" = as.numeric(cor2$estimate),
      "p.value" = cor2$p.value,
      "n" = n2
    ),
    "p.value.twosided" = as.numeric(p.value),
    "p.value.onesided" = as.numeric(p.value) / 2
  )
  cat(paste(sep="",
          "cor1: r=", format(result$cor1$estimate, digits=3), ", p=", format(result$cor1$p.value, digits=3), ", n=", result$cor1$n, "\n",
          "cor2: r=", format(result$cor2$estimate, digits=3), ", p=", format(result$cor2$p.value, digits=3), ", n=", result$cor2$n, "\n",
          "diffence: p(one-sided)=", format(result$p.value.onesided, digits=3), ", p(two-sided)=", format(result$p.value.twosided, digits=3), "\n"
  ))
  return(result);
}
```


# Item Correlations
```{r}
CalcFergDelta <- function(TotalScores, NumGrades) {
  NumStudents <- sum(!is.na(TotalScores))
  Frequencies <- as.vector(table(TotalScores))
  FergDelta <- ((NumStudents^2) - sum(Frequencies^2))/((NumStudents^2) - ((NumStudents^2)/(NumGrades + 1)))
  return(FergDelta)
}

Pre_cols2 <- c(Pre_cols, 'PreScores')
Post_cols2 <- c(Post_cols, 'PostScores')

#ColNames <- c('Q1A', 'Q1B', 'Q1C', 'Q1D', 'Q1E', 'Q2A', 'Q2B', 'Q2C', 'Q2D', 'Q2E', 'Q3A', 'Q3B', 'Q3C', 'Q3D', 'Q3E', 'Q4A', 'Q4B', 'TotalScores')

#ColNames <- c('Q1B', 'Q1D', 'Q1E', 'Q2B', 'Q2D', 'Q2E', 'Q3B', 'Q3C', 'Q3D', 'Q3E', 'Q4A', 'Q4B', 'TotalScores')

ColNames <- c('Q1B', 'Q1D', 'Q1E', 'Q2B', 'Q2D', 'Q2E', 'Q3B', 'Q3D', 'Q3E', 'Q4B', 'TotalScores')

df1 <- df_matched_CR[, Pre_cols2]
df2 <- df_matched_CR[, Post_cols2]

colnames(df1) <- ColNames
colnames(df2) <- ColNames

df <- rbind(df1, df2)

for(Question in ColNames){
  print(Question)
  Result <- cor.diff.test(df1[, Question], df1$TotalScores, df2[, Question], df2$TotalScores)
  print(Result$p.value.twosided)
}

cor(df1)[, 'TotalScores']
cor(df2)[, 'TotalScores']
Corr_Matrix <- cor(df)[, 'TotalScores']
Corr_Matrix['Q3D'] <- cor(df2)['Q3D', 'TotalScores']
PlotSeries <- melt(Corr_Matrix[ColNames[1:10]])

ggplot(PlotSeries, aes(x = rownames(PlotSeries), y = value)) +
  geom_point(size = 3) +
  theme(text = element_text(size = 20)) +
  labs(x = 'Question', y = 'Correlation with Total Score')

length(unique(df1$TotalScores))
length(unique(df2$TotalScores))

CalcFergDelta(df1$TotalScores, length(unique(df1$TotalScores)))
CalcFergDelta(df2$TotalScores, length(unique(df2$TotalScores)))
```

# Holm-Bonferroni correction on p-values
```{r}
# Enter p-values calculated above in order to re-adjust

p_vals <- c(0.0406, 0.147, 0.448, 0.318, 0.0238, 0.0087, 0.44, 0.543, 0.0915)

p.adjust(p_vals, method = "holm")
```

# Cronbach's alpha
```{r}
psych::alpha(df_matched_CR[, Pre_cols])
psych::alpha(df_matched_CR[, Post_cols])
```

# Principal Components
```{r}
df1 <- df_matched_CR[, Pre_cols]

df2 <- df_matched_CR[, Post_cols]

Pre_PCA <- prcomp(df1, scale = TRUE)
Pre_PCA
summary(Pre_PCA)

Post_PCA <- prcomp(df2, scale = TRUE)
Post_PCA
summary(Post_PCA)

for (i in 1:nrow(Pre_PCA$rotation)){
  print(Pre_PCA$rotation[, i] %*% Post_PCA$rotation[, i])
}
```

# Test-retest
```{r}
# P1112 Cornell
P1112_df <- df_pre_CR %>%
  filter(Class_ID %in% c('R_2xOT2Y1NtNiseCk', 'R_1LHvn3R5Afj8eUc', 'R_3ijRcPfXo8MUfFj'))

P1112_df %>%
  group_by(Class_ID) %>%
  summarize(Avg = mean(PreScores), sd95 = 1.96 * sd(PreScores)/sqrt(n()), n())

mod_P1112 <- aov(PreScores ~ Class_ID, data = P1112_df)
summary(mod_P1112)
etaSquared(mod_P1112)

# P1116 Cornell
P1116_df <- df_pre_CR %>%
  filter(Class_ID %in% c('R_1Oko8BpPfb9rt0G', 'R_2R8MnTyv2jFgPzA', 'R_1IB300CxBKh0Tw7'))

P1116_df %>%
  group_by(Class_ID) %>%
  summarize(Avg = mean(PreScores), sd95 = 1.96 * sd(PreScores)/sqrt(n()), n())

mod_P1116 <- aov(PreScores ~ Class_ID, data = P1116_df)
summary(mod_P1116)
etaSquared(mod_P1116)

# P2214 Cornell
P2214_df <- df_pre_CR %>%
  filter(Class_ID %in% c('R_yvBX55C72Ye8W1b', 'R_2DTys2sMNEPNUas'))
  
P2214_df %>%
  group_by(Class_ID) %>%
  summarize(Avg = mean(PreScores), sd95 = 1.96 * sd(PreScores)/sqrt(n()), n())

P2214_df[, c('Class_ID', 'PreScores')]

t.test(PreScores ~ Class_ID, P2214_df, var.equal = TRUE)
effsize::cohen.d(PreScores ~ Class_ID, P2214_df)

mod_P2214 <- aov(PreScores ~ Class_ID, data = P2214_df)
summary(mod_P2214)
etaSquared(mod_P2214)

# P510 Cornell
P510_df <- df_pre_CR %>%
  filter(Class_ID %in% c('R_2E3I53tWJ18Yrh1', 'R_1QDH836nn3XsCEC'))
 
P510_df %>% 
  group_by(Class_ID) %>%
  summarize(Avg = mean(PreScores), sd95 = 1.96 * sd(PreScores)/sqrt(n()), n())

t.test(PreScores ~ Class_ID, P510_df, var.equal = TRUE)
effsize::cohen.d(PreScores ~ Class_ID, P510_df)

mod_P510 <- aov(PreScores ~ Class_ID, data = P510_df)
summary(mod_P510)
etaSquared(mod_P510)

# P121 Maine
Maine_df <- df_pre_CR %>%
  filter(Class_ID %in% c('R_2t4FRFtgLNCF2Ng', 'R_33svFR3Dzit5gMP', 'R_eDQgZq5IOwNJ0SB'))

Maine_df[Maine_df$Class_ID == 'R_eDQgZq5IOwNJ0SB', c('Class_ID')] = 'R_33svFR3Dzit5gMP'

Maine_df %>%
  group_by(Class_ID) %>%
  summarize(Avg = mean(PreScores), sd95 = 1.96 * sd(PreScores)/sqrt(n()), n())

t.test(PreScores ~ Class_ID, Maine_df, var.equal = TRUE)
effsize::cohen.d(PreScores ~ Class_ID, Maine_df)

mod_Maine <- aov(PreScores ~ Class_ID, data = Maine_df)
summary(mod_Maine)
etaSquared(mod_Maine)

# P216 Kansas
Kansas_df <- df_pre_CR %>%
  filter(Class_ID %in% c('R_DnPBuVnC0UjmC1b', 'R_1eRcOhZpre7mhcC'))
  
Kansas_df %>%
  group_by(Class_ID) %>%
  summarize(Avg = mean(PreScores), sd95 = 1.96 * sd(PreScores)/sqrt(n()), n())

t.test(PreScores ~ Class_ID, Kansas_df, var.equal = TRUE)
effsize::cohen.d(PreScores ~ Class_ID, Kansas_df)

mod_Kansas <- aov(PreScores ~ Class_ID, data = Kansas_df)
summary(mod_Kansas)
etaSquared(mod_Kansas)
```


# Partial Sample Reliability
```{r}
df_Reg <- df_matched_CR %>%
  select(Lab_Level, Lab_Type, PreScores, PostScores)

df_Unmatched_Pre <- df_pre_CR %>%
  filter(is.na(PostScores) | (Survey_y == 'F')) %>%
  select(PreScores)

df_Unmatched_Pre %>%
  summarize(n(), mean(PreScores), 1.96 * sd(PreScores)/sqrt(n()))

df_Unmatched_Post <- df_post_CR %>%
  filter(is.na(PreScores) | (Survey_x == 'F')) %>%
  select(PostScores)

df_Unmatched_Post %>%
  summarize(n(), mean(PostScores), 1.96 * sd(PostScores)/sqrt(n()))

t.test(df_Reg$PreScores, df_Unmatched_Pre$PreScores)
effsize::cohen.d(df_Reg$PreScores, df_Unmatched_Pre$PreScores)
t.test(df_Reg$PostScores, df_Unmatched_Post$PostScores)
effsize::cohen.d(df_Reg$PostScores, df_Unmatched_Post$PostScores)
```

# MCAR? Check on students who filled out one FR and one CR
```{r}
df_Post_F <- df_cleaned %>%
  filter((Survey_x == 'C') & (Survey_y == 'F')) %>%
  select(PreScores)

df_Pre_F <- df_cleaned %>%
  filter((Survey_x == 'F') & (Survey_y == 'C')) %>%
  select(PostScores)

t.test(df_Matched$PreScores, df_Post_F$PreScores)
cohen.d(df_Matched$PreScores, df_Post_F$PreScores)
t.test(df_Matched$PostScores, df_Pre_F$PostScores)
cohen.d(df_Matched$PostScores, df_Pre_F$PostScores)
```



# Check differences in item difficulty for matched an unmatched students
```{r}
df_Matched <- df_cleaned %>%
  filter((Survey_x == 'C') & (Survey_y == 'C')) %>%
  select(Pre_cols, Post_cols)

df_Unmatched_Pre <- df_cleaned %>%
  filter((Survey_x == 'C') & (Survey_y != 'C')) %>%
  select(Pre_cols)

df_Unmatched_Post <- df_cleaned %>%
  filter((Survey_x != 'C') & (Survey_y == 'C')) %>%
  select(Post_cols)

for (Q in Pre_cols) {
  print(Q)
  print(tidy(wilcox.test(df_Matched[, Q], df_Unmatched_Pre[, Q]))$p.value)
  print(cohen.d(df_Matched[, Q], df_Unmatched_Pre[, Q])$estimate)
}

for (Q in Post_cols) {
  print(Q)
  print(mean(df_Matched[, Q]))
  print(mean(df_Unmatched_Post[, Q]))
  print(tidy(wilcox.test(df_Matched[, Q], df_Unmatched_Post[, Q]))$p.value)
  print(cohen.d(df_Matched[, Q], df_Unmatched_Post[, Q])$estimate)
}

```



# Summary function for paired t-tests
```{r}
t_test_summary = function(x1, x2, paired = FALSE) {
  t_results <- tidy(t.test(x1, x2, paired = paired))
  
  Summary_df <- data.frame(Mean1 = mean(x1), SE1_95 = 1.96 * sd(x1)/sqrt(length(x1)), Mean2 = mean(x2), SE2_95 = 1.96 * sd(x2)/sqrt(length(x2)), p.value = t_results$p.value, T.stat = t_results$statistic, df = t_results$parameter, Cohen.d = effsize::cohen.d(x1, x2, paired = paired)$estimate)
  
  return(Summary_df)
}
```



# Level Pre-post shifts
```{r}
df1 <- df_Reg %>%
  mutate(Lab_Level = ifelse(Lab_Level == 'FY', 'FY', 'BFY'))

table(df1$Lab_Level)

df1 %>%
  group_by(Lab_Level) %>%
  summarize(mean(PreScores), n())

df_FY <- df1 %>%
  filter(Lab_Level == 'FY')

df_BFY <- df1 %>%
  filter(Lab_Level == 'BFY')

t_test_summary(df_FY$PreScores, df_FY$PostScores, paired = TRUE)
t_test_summary(df_BFY$PreScores, df_BFY$PostScores, paired = TRUE)
```

# Compare pre-scores across lab levels...and Experts
```{r}
t_test_summary(df_FY$PreScores, df_BFY$PreScores)
#t_test_summary(df_FY$PreScores, df_Grad$PreScores)
#t_test_summary(df_BFY$PreScores, df_Grad$PreScores)

df_Experts <- read.xlsx('C:/Users/Cole/Documents/GRA_Summer2018/Surveys/Experts/Experts_11S.xlsx', sheetIndex = 1)

t_test_summary(df_FY$Pre, df_Experts$TotalScores)
t_test_summary(df_BFY$Pre, df_Experts$TotalScores)

nrow(df_Experts)

df_Experts_level <- df_Experts %>%
  mutate(Lab_Level = 'Experts') %>%
  rename(PreScores = TotalScores) %>%
  select(Lab_Level, PreScores)

df_comb <- rbind(df_FY[, c('Lab_Level', 'PreScores')], df_BFY[, c('Lab_Level', 'PreScores')], df_Experts_level)

mod <- aov(PreScores ~ Lab_Level, df_comb)
summary(mod)
etaSquared(mod)

df_comb$Lab_Level <- ordered(df_comb$Lab_Level, levels = c('FY', 'BFY', 'Experts'))
ggplot(df_comb, aes(x = Lab_Level, y = PreScores)) +
  geom_boxplot(lwd = 2, fatten = 1) +
  theme_minimal() +
  theme(text = element_text(size = 20)) +
  labs(x = 'Physics Maturity', y = 'Score on Pre-PLIC')
```


# Examine lab impacts
```{r}
table(df_FY$Lab_Type)
df_FY

colnames(df_FY) <- c('Lab_Level', 'Lab', 'Pre', 'Post')

model <- aov(Post ~ Pre + Lab, df_FY)
summary(model)
etaSquared(model)

fit <- lm(Post ~ Pre + factor(Lab), data = df_FY)
Result <- tidy(summary(fit))
Result$confint95 <- 1.96 * Result$std.error
Result

df_FY_melt = melt(df_FY)
colnames(df_FY_melt) <- c('Lab_Level', 'Lab', 'Survey', 'Score')

ggplot(df_FY_melt, aes(x = Lab, y = Score)) +
  geom_boxplot(lwd = 2, fatten = 1, aes(color = Survey)) +
  theme_minimal() +
  theme(text = element_text(size = 20), legend.position = c(0.1, 0.9), legend.title = element_blank(), legend.background = element_blank()) +
  scale_color_manual(values=c("#a6bddb", "#2b8cbe"))
```

```{r}
hist(df_FY$Pre)
hist(df_BFY$PreScores)
hist(df_Grad$PreScores)
hist(df_FY$Post)
hist(df_BFY$PostScores)
hist(df_Grad$PostScores)
hist(df_Experts$TotalScores)
max(df_Experts$TotalScores)
```

```{r}

```



